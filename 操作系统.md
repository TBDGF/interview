## 进程和线程

**进程的缺点**

- 进程只能在一个时间干一件事，如果想同时干两件事或多件事，进程就无能为力了。
- 进程在执行的过程中如果阻塞，例如等待输入，整个进程就会挂起，即使进程中有些工作不依赖于输入的数据，也将无法执行。





一、**线程的基本概念**

线程是进程中执行运算的最小单位，是进程中的一个实体，是被系统独立调度和分派的基本单位，线程自己不拥有系统资源，只拥有一点在运行中必不可少的资源，但它可与同属一个进程的其它线程共享进程所拥有的全部资源。一个线程可以创建和撤消另一个线程，同一进程中的多个线程之间可以并发执行。

多线程好处 ：

（1）易于调度。

（2）提高并发性。通过线程可方便有效地实现并发性。进程可创建多个线程来执行同一程序的不同部分。

（3）开销少。创建线程比创建进程要快，所需开销很少。

（4）利于充分发挥多处理器的功能。通过创建多线程进程，每个线程在一个处理器上运行，从而实现应用程序的并发性，使每个处理器都得到充分运行。

二、**进程与线程**

**进程：**每个进程都有独立的代码和数据空间（进程上下文），进程间的切换会有较大的开销，一个进程包含1--n个线程。（进程是资源分配的最小单位）

**线程：**同一类线程共享代码和数据空间，每个线程有独立的运行栈和程序计数器(PC)，线程切换开销小。（线程是cpu调度的最小单位）

线程和进程一样分为五个阶段：**创建、就绪、运行、阻塞、终止。**

![img](https://images2018.cnblogs.com/blog/1418466/201808/1418466-20180813190253839-297059020.png)

![img](https://images2018.cnblogs.com/blog/1418466/201808/1418466-20180813190923313-2036091644.png)

 

**多进程是指操作系统能同时运行多个任务（程序）。**

**多线程是指在同一程序中有多个顺序流在执行。**

每个正在系统上运行的程序都是一个进程。每个进程包含一到多个线程。进程也可能是整个程序或者是部分程序的动态执行。线程是一组指令的集合，或者是程序的特殊段，它可以在程序里独立执行。也可以把它理解为代码运行的上下文。所以线程基本上是轻量级的进程，它负责在单个程序里执行多任务。通常由操作系统负责多个线程的调度和执行。

在Java中，一个应用程序可以包含多个线程。每个线程执行特定的任务，并可与其他线程并发执行多线程使系统的空转时间最少，提高CPU利用率、多线程编程环境用方便的模型隐藏CPU在任务间切换的事实在Java程序启动时，一个线程立刻运行，该线程通常称为程序的主线程。

主线程的重要性体现在两个方面：

1、它是产生其他子线程的线程。

2、通常它必须最后完成执行，因为它执行各种关闭动作。

三、**进程与线程的区别**：

（1）调度：线程作为调度和分配的基本单位，进程作为拥有资源的基本单位

（2）并发性：不仅进程之间可以并发执行，同一个进程的多个线程之间也可并发执行

（3）拥有资源：进程是拥有资源的一个独立单位，线程不拥有系统资源，但可以访问隶属于进程的资源.

（4）系统开销：在创建或撤消进程时，由于系统都要为之分配和回收资源，导致系统的开销明显大于创建或撤消线程时的开销。

 四、**进程和线程的关系**：

（1）一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。

（2）资源分配给进程，同一进程的所有线程共享该进程的所有资源。

（3）处理机分给线程，即真正在处理机上运行的是线程。

（4）线程在执行过程中，需要协作同步。不同进程的线程间要利用消息通信的办法实现同步。线程是指进程内的一个执行单元,也是进程内的可调度实体.

**总结**

线程和进程的区别在于，子进程和父进程有不同的代码和数据空间，而多个线程则共享数据空间，每个线程有自己的执行堆栈和程序计数器为其执行上下文。多线程主要是为了节约CPU时间，发挥利用，根据具体情况而定，线程的运行中需要使用计算机的内存资源和CPU。



## 线程和进程的区别

进程，在一定的环境下，把静态的程序代码运行起来，通过使用不同的资源，来完成一定的任务。比如说，进程的环境包括环境变量，进程所掌控的资源，有中央处理器，有内存，打开的文件，映射的网络端口等等。

一个系统中，有很多进程，它们都会使用内存。为了确保内存不被别人使用，每个进程所能访问的内存都是圈好的。一人一份，谁也不干扰谁。

线程作为进程的一部分，扮演的角色就是怎么利用中央处理器去运行代码。同⼀个进程内多个线程之间可以共享代码段、数据段、打开的⽂件等资源，但每个线程各⾃都有⼀套独⽴的寄存器和栈，这样可以确保线程的控制流是相对独⽴的。

- 线程在进程下运行，一个进程可以包含多个线程
- 不同进程间数据较难共享，但不同线程间数据很易共享
- 无论是多进程的资源开销还是进程间的切换开销，进程都要比线程开销大
- 进程间不会相互影响，一个线程挂掉可能会导致整个进程挂掉





## 线程的共享资源

| 线程共享资源 | 线程独享资源 |
| :----------- | ------------ |
| 地址空间     | 程序计数器   |
| 全局变量     | 寄存器       |
| 打开的文件   | 栈           |
| 子进程       | 状态字       |



## 线程的状态

**OS的线程状态**

![OS Thread state](https://img2020.cnblogs.com/blog/1842338/202110/1842338-20211011115632881-62622134.png)

**JVM的线程状态**

![img](https://img2020.cnblogs.com/blog/1842338/202110/1842338-20211011115638685-1098558362.jpg)





## 线程和协程

操作系统在线程等待IO的时候，会阻塞当前线程，切换到其它线程，这样在当前线程等待IO的过程中，其它线程可以继续执行。当系统线程较少的时候没有什么问题，但是当线程数量非常多的时候，却产生了问题。**一是系统线程会占用非常多的内存空间，二是过多的线程切换会占用大量的系统时间。**

协程运行在线程之上，当一个协程执行完成后，可以选择主动让出，让另一个协程运行在当前线程之上。**协程并没有增加线程数量，只是在线程的基础之上通过分时复用的方式运行多个协程**，而且协程的切换在用户态完成，切换的代价比线程从用户态到内核态的代价小很多。

**注意事项**

假设协程运行在线程之上，并且协程调用了一个阻塞IO操作，这时候会发生什么？实际上操作系统并不知道协程的存在，它只知道线程，**因此在协程调用阻塞IO操作的时候，操作系统会让线程进入阻塞状态，当前的协程和其它绑定在该线程之上的协程都会陷入阻塞而得不到调度，这往往是不能接受的。**

因此在协程中不能调用导致线程阻塞的操作。也就是说，协程只有和异步IO结合起来，才能发挥最大的威力。

那么如何处理在协程中调用阻塞IO的操作呢？一般有2种处理方式：

1. **在调用阻塞IO操作的时候，重新启动一个线程去执行这个操作，等执行完成后，协程再去读取结果。这其实和多线程没有太大区别。**
2. **对系统的IO进行封装，改成异步调用的方式，这需要大量的工作，最好寄希望于编程语言原生支持。**

协程对计算密集型的任务也没有太大的好处，计算密集型的任务本身不需要大量的线程切换，因此协程的作用也十分有限，反而还增加了协程切换的开销。

**异步变同步的调用方式只是一种编程方式，不管是用线程还是用协程都可以实现这种编程方式，好处是不用在处理非常多的回调。**

**总结**

在有大量IO操作业务的情况下，我们采用协程替换线程，可以到达很好的效果，一是降低了系统内存，二是减少了系统切换开销，因此系统的性能也会提升。

在协程中尽量不要调用阻塞IO的方法，比如打印，读取文件，Socket接口等，除非改为异步调用的方式，并且协程只有在IO密集型的任务中才会发挥作用。

**协程只有和异步IO结合起来才能发挥出最大的威力。**



 **协程相比线程的优势**

1. 协程比线程更细粒度，协程运行在线程之上，多个协程可以由一个或多个线程管理。
2. 协程上下文切换较快，少于线程之间切换的开销。协程的切换，仅仅需要改变寄存器的数值，cpu便会从需要切换的协程指定位置继续运行。
3. 同一个线程之内的协程调度不需要锁机制，因为只有一个线程，不存在同时写变量冲突，执行效率比多线程高很多。



## 进程间通信的方式

1. 管道pipe：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。
2. 命名管道FIFO：有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。有名管道严格遵循**先进先出(first in first out)**。有名管道以磁盘文件的方式存在，可以实现本机任意两个进程通信。
3. 信号(Signal) ：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生；
4. 消息队列MessageQueue：消息队列是消息的[链表](),具有特定的格式,存放在内存中并由消息队列标识符标识。管道和消息队列的通信数据都是先进先出的原则。与管道（无名管道：只存在于内存中的文件；命名管道：存在于实际的磁盘介质或者文件系统）不同的是消息队列存放在内核中，只有在内核重启(即，操作系统重启)或者显示地删除一个消息队列时，该消息队列才会被真正的删除。消息队列可以实现消息的随机查询,消息不一定要以先进先出的次序读取,也可以按消息的类型读取.比 FIFO 更有优势。**消息队列克服了信号承载信息量少，管道只能承载无格式字 节流以及缓冲区大小受限等缺。**
5. 共享存储SharedMemory：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据的更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。可以说这是最有用的进程间通信方式。
6. 信号量Semaphore：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
7. 套接字Socket：此方法主要用于在客户端和服务器之间通过网络进行通信。套接字是支持 TCP/IP 的网络通信的基本操作单元，可以看做是不同主机之间的进程进行双向通信的端点，简单的说就是通信的两方的一种约定，用套接字中的相关函数来完成通信过程。



### 信号

信号是Linux系统中用于进程之间通信或操作的一种机制，信号可以在任何时候发送给某一进程，而无须知道该进程的状态。如果该进程并未处于执行状态，则该信号就由内核保存起来，知道该进程恢复执行并传递给他为止。如果一个信号被进程设置为阻塞，则该信号的传递被延迟，直到其阻塞被取消时才被传递给进程。

Linux提供了几十种信号，分别代表着不同的意义。信号之间依靠他们的值来区分，但是通常在程序中使用信号的名字来表示一个信号。在Linux系统中，这些信号和以他们的名称命名的常量被定义在/usr/includebitssignum.h文件中。通常程序中直接包含<signal.h>就好。

 

信号是在软件层次上对中断机制的一种模拟，是一种异步通信方式，信号可以在用户空间进程和内核之间直接交互。内核也可以利用信号来通知用户空间的进程来通知用户空间发生了哪些系统事件。信号事件有两个来源：

1）硬件来源，例如按下了cltr+C，通常产生中断信号sigint

2）软件来源，例如使用系统调用或者命令发出信号。最常用的发送信号的系统函数是kill,raise,setitimer,sigation,sigqueue函数。软件来源还包括一些非法运算等操作。

 

一旦有信号产生，用户进程对信号产生的相应有三种方式：

1）执行默认操作，linux对每种信号都规定了默认操作。

2）捕捉信号，定义信号处理函数，当信号发生时，执行相应的处理函数。

3）忽略信号，当不希望接收到的信号对进程的执行产生影响，而让进程继续执行时，可以忽略该信号，即不对信号进程作任何处理。

有两个信号是应用进程无法捕捉和忽略的，即SIGKILL和SEGSTOP，这是为了使系统管理员能在任何时候中断或结束某一特定的进程。

### 管道

管道允许在进程之间按先进先出的方式传送数据，是进程间通信的一种常见方式。

管道是Linux 支持的最初Unix IPC形式之一，具有以下特点：

1) 管道是**半双工的**，数据只能向一个方向流动；**需要双方通信时，需要建立起两个管道**；

2) 匿名管道只能用于父子进程或者兄弟进程之间（具有亲缘关系的进程）；

3) 单独构成一种独立的文件系统：管道对于管道两端的进程而言，就是一个文件，但它不是普通的文件，它不属于某种文件系统，而是自立门户，单独构成一种文件系统，并且只存在与内存中。

 

管道分为pipe（无名管道）和fifo（命名管道）两种，除了建立、打开、删除的方式不同外，这两种管道几乎是一样的。他们都是通过内核缓冲区实现数据传输。

- pipe用于相关进程之间的通信，例如父进程和子进程，它通过pipe()系统调用来创建并打开，当最后一个使用它的进程关闭对他的引用时，pipe将自动撤销。
- FIFO即命名管道，**在磁盘上有对应的节点，但没有数据块**——换言之，只是拥有一个名字和相应的访问权限，通过mknode()系统调用或者mkfifo()函数来建立的。一旦建立，任何进程都可以通过文件名将其打开和进行读写，而不局限于父子进程，当然前提是进程对FIFO有适当的访问权。当不再被进程使用时，FIFO在内存中释放，但磁盘节点仍然存在。

管道的实质是一个内核缓冲区，进程以先进先出的方式从缓冲区存取数据：管道一端的进程顺序地将进程数据写入缓冲区，另一端的进程则顺序地读取数据，该缓冲区可以看做一个循环队列，读和写的位置都是自动增加的，一个数据只能被读一次，读出以后再缓冲区都不复存在了。当缓冲区读空或者写满时，有一定的规则控制相应的读进程或写进程是否进入等待队列，当空的缓冲区有新数据写入或慢的缓冲区有数据读出时，就唤醒等待队列中的进程继续读写。

![img](https://images2015.cnblogs.com/blog/364303/201608/364303-20160828225350723-1962168981.png)

### 命名管道

和无名管道的主要区别在于，命名管道有一个名字，命名管道的名字对应于一个磁盘索引节点，有了这个文件名，任何进程有相应的权限都可以对它进行访问。

而无名管道却不同，进程只能访问自己或祖先创建的管道，而不能访任意访问已经存在的管道——因为没有名字。



### 消息队列

消息队列，就是一个消息的链表，是一系列保存在内核中消息的列表。用户进程可以向消息队列添加消息，也可以向消息队列读取消息。

消息队列与管道通信相比，其优势是对每个消息指定特定的消息类型，接收的时候不需要按照队列次序，而是可以根据自定义条件接收特定类型的消息。

可以把消息看做一个记录，具有特定的格式以及特定的优先级。对消息队列有写权限的进程可以向消息队列中按照一定的规则添加新消息，对消息队列有读权限的进程可以从消息队列中读取消息。

### 共享内存

共享内存允许两个或多个进程共享一个给定的存储区，这一段存储区可以被两个或两个以上的进程映射至自身的地址空间中，一个进程写入共享内存的信息，可以被其他使用这个共享内存的进程，通过一个简单的内存读取错做读出，从而实现了进程间的通信。

采用共享内存进行通信的一个主要好处是效率高，因为进程可以直接读写内存，而不需要任何数据的拷贝，对于像管道和消息队里等通信方式，则需要再内核和用户空间进行四次的数据拷贝，而共享内存则只拷贝两次：一次从输入文件到共享内存区，另一次从共享内存到输出文件。

一般而言，进程之间在共享内存时，并不总是读写少量数据后就解除映射，有新的通信时在重新建立共享内存区域；而是保持共享区域，直到通信完毕为止，这样，数据内容一直保存在共享内存中，并没有写回文件。共享内存中的内容往往是在解除映射时才写回文件，因此，采用共享内存的通信方式效率非常高。

### 信号量

信号量（semaphore）与已经介绍过的 IPC 结构不同，它是一个计数器。信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。

1、特点
信号量用于进程间同步，若要在进程间传递数据需要结合共享内存。

信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作。

每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数。

支持信号量组。

2、原型
最简单的信号量是只能取 0 和 1 的变量，这也是信号量最常见的一种形式，叫做二值信号量（Binary Semaphore）。而可以取多个正整数的信号量被称为通用信号量。

## Linux 下的信号量函数都是在通用的信号量数组上进行操作，而不是在一个单一的二值信号量上进行操作。

### socket

IP层的ip地址可以唯一标示主机，而TCP层协议和端口号可以唯一标示主机的一个进程，这样我们可以利用ip地址＋协议＋端口号唯一标示网络中的一个进程。

能够唯一标示网络中的进程后，它们就可以利用socket进行通信了。socket是在应用层和传输层之间的一个抽象层，它把TCP/IP层复杂的操作抽象为几个简单的接口供应用层调用已实现进程在网络中通信。

------

## 锁的类型

### 互斥锁

互斥锁指代相互排斥，它是最基本的同步方式。互斥锁用于保护临界区，以保证任何时刻只有一个线程在执行其中的代码（假设互斥锁由多个线程共享），或者任何时刻只有一个进程在执行其中的代码。

**特点**

- 多个线程访问共享数据的时候是串行的
- 效率低

**Barkey锁**

- 每个线程想进入临界区之前都会升起自己的旗帜，并得到一个序号。然后升起旗帜的线程中序号最小的线程才能进入临界区。 
- 每个线程离开临界区的时候降下自己的旗帜。

### 读写锁

读写锁用于读与写之间作区分。读写锁的分配规则如下：

1. 只要没有线程持有某个给定的读写锁用于读或用于写时，那么任意数目的线程可以持有该读写锁用于读。
2. 仅当没有线程持有某个给定的读写锁用于读或用于写时，才能分配该读写锁用于写。

**特点**

- 读共享 - 并行处理，线程A加读锁成功, 又来了三个线程, 做读操作, 可以加锁成功
- 写独占，线程A加写锁成功, 又来了三个线程, 做读操作, 三个线程阻塞
- 读写不能同时，写的优先级高，线程A加读锁成功, 又来了B线程加写锁阻塞, 又来了C线程加读锁阻塞

**适用场景**

程序中的读操作>写操作的时候

### 乐观锁和悲观锁

**悲观锁**

总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。

**乐观锁**

总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量。

------

## 虚拟内存





### 虚拟地址空间

在早期的计算机中，程序是直接运行在物理内存上的，那个时候的计算机和程序内存都很小。程序运行时会把其全部加载到内存，只要程序所需的内存不超过计算机剩余内存就不会出现问题。

 但由于程序是可以直接访问物理内存的，这也带来了内存数据的不安全性，轻则程序挂掉，重则操作系统崩溃。

 所以，我们希望程序间的内存数据是安全的互不影响的。同时计算机程序直接运行在物理内存上也导致了内存使用率较低，程序运行内存地址不确定，不同的运行顺序甚至会出错。此时在程序的执行过程中，已经存在着大量在物理内存和硬盘之间的数据交换过程。

 基于以上问题，那我们可以是不是考虑在物理内存之上增加一个中间层，让程序通过虚拟地址去间接的访问物理内存呢。通过虚拟内存，每个进程好像都可以独占内存一样，每个进程看到的内存都是一致的，这称为虚拟地址空间。（这种思想在现在也用的很广泛，例如很多优秀的中间层：Nginx、Redis等等）

 这样只要系统处理好虚拟地址到物理地址的映射关系，就可以保证不同的程序访问不同的内存区域，就可以达到物理内存地址隔离的效果，进而保证数据的安全性。

 

### 分段

分段机制就是把虚拟地址空间中的虚拟内存组织成一些长度可变的称为段的内存块单元。

段可以用来存放程序的代码、数据和堆栈，或者用来存放系统数据结构。

操作系统分配给进程的内存空间中包含五种段：数据段、代码段、BSS、堆、栈。

- 数据段：存放程序中的静态变量和已初始化且不为零的全局变量。


- 代码段：存放可执行文件的操作指令，代码段是只读的，不可进行写操作。这部分的区域在运行前已知其大小。


- BSS段( Block Started By Symbol)：存放未初始化的全局变量，在变量使用前由运行时初始化为零。


- 堆：存放进程运行中被动态分配的内存，其大小不固定。


- 栈：存放程序中的临时的局部变量和函数的参数值。

![640?wx_fmt=png](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9KYmlhZUtucEd1NmlhTHM5ZWs2eGZaZUxFMkd6c3RKRk5Cd1daRUx3VkNuRndRUFpOTU4wNFlwM2JuRnBMaWI0VVVKUW5PZXNVVlBQVmdveFZyUXV4UWZpYWcvNjQw?x-oss-process=image/format,png)

通过分段机制，我们可以更好的控制不同段的属性，这有利于内存的组织安排，可以对不同的属性代码、数据进行更方便的管理。如果是打乱的放在内存中，那么读写属性就很难控制。

程序运行地址和物理地址的隔离保证了程序内存数据的安全性，也解决了同一个程序运行地址不确定的问题，但是物理内存使用效率低下的问题依然没有得到解决，因为分段机制映射的是一片连续的物理内存。



### 分页

分页其实就是把段空间更细分了一下，粒度更小。此时物理内存被划分为一小块一小块，每块被称为帧(Frame)。分配内存时，帧是分配时的最小单位。

在分段方法中，每次程序的运行都会被全部加载到虚拟内存中；而分页方法则不同，单位不是整个程序，而是某个“页”，一段虚拟地址空间组成的某一页映射到一段物理地址空间组成的某一页。它将少部分要运行的代码加载到虚拟内存中，通过映射在物理内存中运行，从而提高了物理内存的使用率。

![640?wx_fmt=jpeg](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy9KYmlhZUtucEd1NmlhTHM5ZWs2eGZaZUxFMkd6c3RKRk5CZzVOM0xjU2ljYjFLbnBneThMQzNRUkJVRThlaWFyaWNGUWlhenJIZlRkWk9KSHRCeFJONkZZaktwQS82NDA?x-oss-process=image/format,png)

为了方便CPU高效执行管理物理内存，每一次都需要从虚拟内存中拿一个页的代码放到物理内存。虚拟内存页有三种状态，分别是未分配、已缓存和未缓存状态。

**未分配**：指的是未被操作系统分配或者创建的，未分配的虚拟页不存在任何数据和代码与它们关联，因此不占用磁盘资源；

**已缓存**：表示的是物理内存中已经为该部分分配的，存在虚拟内存和物理内存映射关系的；

**未缓存**：指的是已经加载到虚拟内存中的，但是未在物理内存中建立映射关系的。



**页表**

虚拟内存中的一些虚拟页是要缓存在物理内存中才能被执行的，因此操作系统存在一种机制用来判断某个虚拟页是否被缓存在物理内存中，还需要知道这个虚拟页存放在磁盘上的哪个位置，从而在物理内存中选择空闲页或者更新缓存页，并将需要的虚拟页从磁盘复制到物理内存中。这些功能是由软硬件结合完成的，其存放在物理内存中一个叫页表的数据结构中。

虚拟内存和物理内存的映射通过页表(page table)来实现。每个页表实际上是一个数组，数组中的每个元素称为页表项(PTE, page table entry)，每个页表项负责把虚拟页映射到物理页上。在物理内存中，每个进程都有自己的页表。

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9KYmlhZUtucEd1NmlhTHM5ZWs2eGZaZUxFMkd6c3RKRk5CbUhqeDVleGdkMU5WdHF1UE9lTDRsaWJMc3NiN09DRTU1a0Uyek51SkpYSk9nT29uRGJWZFBpYncvNjQw?x-oss-process=image/format,png)

因为有一个表可查询，就会遇到两种情况，一种是命中(Page Hit)，另一种则是未命中(Page Fault)。

命中的时候，即访问到页表中蓝色条目的地址时，因为在 DRAM 中有对应的数据，可以直接访问。

不命中的时候，即访问到 page table 中灰色条目的时候，因为在 DRAM 中并没有对应的数据，所以需要执行缺页中断。

在上图中，四个虚拟页VP1 , VP2, VP4 , VP7 是被缓存在物理内存中。两个虚拟页VP0, VP5还未被分配。但是剩下的虚拟页VP3 ,VP6已经被分配了，但是还没有缓存到物理内存中去执行。



### 段页式

段页式存储组织是分段式和分页式结合的存储组织方法，这样可充分利用分段管理和分页管理的优点。

 (1) 用分段方法来分配和管理虚拟存储器。程序的地址空间按逻辑单位分成基本独立的段，而每一段有自己的段名，再把每段分成固定大小的若干页。

 (2) 用分页方法来分配和管理实存。即把整个主存分成与上述页大小相等的存储块，可装入作业的任何一页。程序对内存的调入或调出是按页进行的。但它又可按段实现共享和保护。



### 虚拟内存的作用

通过虚拟地址空间和页表的回顾，现在大家应该明白为什么要引入虚拟内存了吧。

虚拟内存是计算机系统内存管理的一种技术，虚拟地址空间构成虚拟内存。它使得应用程序认为它拥有连续可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片。还有部分暂时存储在外部磁盘存储器上（Swap），在需要时进行数据交换。

虚拟内存不只是用磁盘空间来扩展物理内存 的意思——这只是扩充内存级别以使其包含硬盘驱动器而已。把内存扩展到磁盘只是使用虚拟内存技术的一个结果。除了扩展内存空间，虚拟内存技术还有隔离运行内存和确定运行地址的作用。

使用虚拟内存主要是基于以下三个方面考虑，也就是说虚拟内存主要有三个作用：

- 作为缓存工具，提高内存利用率：使用 DRAM 当做部分的虚拟地址空间的缓存（虚拟内存就是存储在磁盘上的 N 个连续字节的数组，数组的部分内容会缓存在 DRAM 中）。扩大了内存空间，当发生缺页异常时，将会把内存和磁盘中的数据进行置换。


- 作为内存管理工具，简化内存管理：每个进程都有统一的线性地址空间（但实际上在物理内存中可能是间隔、支离破碎的），在内存分配中没有太多限制，每个虚拟页都可以被映射到任何的物理页上。这样也带来一个好处，如果两个进程间有共享的数据，那么直接指向同一个物理页即可。


- 作为内存保护工具，隔离地址空间：进程之间不会相互影响；用户程序不能访问内核信息和代码。页表中的每个条目的高位部分是表示权限的位，MMU 可以通过检查这些位来进行权限控制（读、写、执行）。

------

## 缺页中断

**缺页中断**

在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。每当所要访问的页面不在内存时，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。

缺页本身是一种中断，与一般的中断一样，需要经过4个处理步骤：

　　1. 保护CPU现场
　　2. 分析中断原因
　　3. 转入缺页中断处理程序进行处理
  4. 恢复CPU现场，继续执行

但是缺页中断时由于所要访问的页面不存在与内存时，有硬件所产生的一种特殊的中断，因此，与一般的中断存在区别：

   1. 在指令执行期间产生和处理缺页中断信号
   2. 一条指令在执行期间，可能产生多次缺页中断
   3. 缺页中断返回时，执行产生中断的那一条指令，而一般的中断返回时，执行下一条指令

**页面置换算法**

进程运行过程中，如果发生缺页中断，而此时内存中有没有空闲的物理块是，为了能够把所缺的页面装入内存，系统必须从内存中选择一页调出到磁盘的对换区。但此时应该把那个页面换出，则需要根据一定的页面置换算法（Page Replacement Algorithm)来确定。

**常见的缓存算法**

- LRU (Least recently used) 最近最少使用，如果数据最近被访问过，那么将来被访问的几率也更高。
- LFU (Least frequently used) 最不经常使用，如果一个数据在最近一段时间内使用次数很少，那么在将来一段时间内被使用的可能性也很小。
- FIFO (Fist in first out) 先进先出， 如果一个数据最先进入缓存中，则应该最早淘汰掉。



------



## 内存分配

一、**代码区**

代码区是用来储存**程序的所有代码**，以及**字符串常量等在编译期间就能确定的值**，在程序的整个生命周期内， 在常量数据区的数据都是可用的。在这个区域内，所有的数据都是只读的，不可以修改本区域的数据，之所以这样，是因为在实际的实现中，最底层内部存储格式的实现会使用特定的优化方案。比如说，编译器可能只把字符串常量存储一次，而在几个重叠的对象里面引用它 。

二、**栈区**

栈区主要存放编译器在需要的时候自动分配，在不需要的时候自动销毁的变量。主要是**局部变量和函数的参数**等，在函数调用和传参的时候，编译器为局部变量或形参开辟空间，注意，在这块空间中，编译器并不会自动对它进行任何的初始化，它所保存的不是0，而是一个随机值（可能是该储存区上次被使用后的值），在函数结束后，所开辟的空间将自动销毁，里面所存的内容将不复存在，也就是释放存储区的内容。 这就是为什么老师们在讲课中，最喜欢用的字眼：参数压栈和弹出。

三、**全局静态（数据）区**

全局静态（数据）区是用来存储**全局静态变量**的存储区域。只有在程序启动的时候才被分配，直到程序开始执行时才被初始化，比如：函数的静态变量就是在程序执行到定义该变量的代码时才被初始化的。在静态区数据区中没有被初始化的区域可以通过void* 指针来访问或操纵，但是，static定义的静态变量只能在本文件中使用，不可在其它文件中声明使用。

四、**堆区**

堆区是一个动态的存储区域，使用库函数**malloc()**和free()，和操作符**new**和delete以及一些相关变量来进行分配和回收，在堆区中，对象的生命周期可以比它村在内存中的生命周期短，换句话说：程序可以获得一片内存区域而不用马上对它进行初始化，同时，在对象被销毁后，也不用马上收回它所占用的内存区，在这段时间内，用户可以还可以用void*型的指针访问这片区域，但是原始对象的非静态区以及成员函数都不能被访问或者操纵，因为我们知道实际上对象已经不存在了。

![图四](https://img-blog.csdnimg.cn/img_convert/f108aa64f7a104628ff1f1ab07f59968.png)



### 堆和栈的区别

1、栈由系统自动分配，而堆是人为申请开辟;

2、栈获得的空间较小，而堆获得的空间较大;

3、栈由系统自动分配，速度较快，而堆一般速度比较慢;

4、栈在函数调用时，函数调用语句的下一条可执行语句的地址第一个进栈，然后函数的各个参数进栈，其中静态变量是不入栈的。而堆一般是在头部用一个字节存放堆的大小，堆中的具体内容是人为安排;

5、栈是连续的空间，而堆是不连续的空间。





## TODO IO系统

[考研复试操作系统面试题（一）-IO系统_春季觉醒的博客-CSDN博客_操作系统考研面试题](https://blog.csdn.net/qq_30719815/article/details/105075312)



## 进程调度算法

[操作系统进程调度算法_xy的博客-CSDN博客_进程调度算法](https://blog.csdn.net/qq_36221862/article/details/55670604)

**先到先服务(FCFS)调度算法** : 从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。 

**短作业优先(SJF)的调度算法** : 从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。 

**时间片轮转调度算法** : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。 

**多级反馈队列调度算法** ：前面介绍的几种进程调度的算法都有一定的局限性。如**短进程优先的调度算法，仅照顾了短进程而忽略了长进程** 。多级反馈队列调度算法既能使高优先级的作业得到响应又能使短作业（进程）迅速完成。，因而它是目前**被公认的一种较好的进程调度算法**，UNIX 操作系统采取的便是这种调度算法。 

**优先级调度** ： 为每个流程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。

<img src="https://img-blog.csdn.net/20160605214232867" alt="img" style="zoom:150%;" />

**先来先服务**

先来先服务(FCFS)调度算法是一种最简单的调度算法，该算法既可用于作业调度，也可用于进程调度。当在作业调度中采用该算法时，每次调度都是从后备作业队列中选择一个或多个最先进入该队列的作业，将它们调入内存，为它们分配资源、创建进程，然后放入就绪队列。在进程调度中采用FCFS算法时，则每次调度是从就绪队列中选择一个最先进入该队列的进程，为之分配处理机，使之投入运行。该进程一直运行到完成或发生某事件而阻塞后才放弃处理机。

来看一个例子，假设有三个进程和它们各自执行时间（以毫秒为单位）如下表：

<img src="../img/1348147106_5559.png" alt="1348147106_5559" style="zoom:200%;" />

那么如果三个进程按照P1, P2, P3的顺序启动的话，按照先到先服务的调度算法，执行过程如下：

<img src="../img/1348147123_9218.png" alt="1348147123_9218" style="zoom:200%;" />

平均等待时间就是(0 + 24 + 27) / 3 = 17毫秒。FCFS算法是非抢占式的，一旦内核将CPU分配给一个进程就不会被释放了，除非进程结束或者请求I/O阻塞。这也是我们之前学习的多任务系统的特点。

**转轮法**

这是一种基于时钟的抢占策略，以一个周期性间隔产生时钟中断，当中断发生时，当前正在运行的进程被置于就绪队列中，然后基于FCFS策略选择下一个就绪作业的运行。这种技术也称时间片，因为每个进程在被抢占前都给定一片时间。

来看下面的例子，假设一个时间片的长度为4毫秒：

![img](https://img-my.csdn.net/uploads/201209/20/1348147300_5996.png)

**最短进程**

该算法从就绪队列中选出下一个“CPU执行期最短”的进程，为之分配处理机。
最短作业优先调度是优先级调度的特例。在优先级调度中我们根据进程的优先级来进行调度，在最短作业优先调度中我们
根据作业的执行时间长短来调度。
通过下面的例子来看看SJF是怎样调度的。

<img src="../img/1348147220_7860.png" alt="1348147220_7860" style="zoom:200%;" />

进程1首先执行了1毫秒，当执行时间更短的进程2进入Ready队列时发生抢占。进程3在进程2执行1毫秒后到来，但是进程3的
执行时间比进程2长。同理进程4的到来也没法抢占进程2，所以进程2可以一直执行到结束。之后是执行时间第二短的进程4
执行，最后是进程1（要看剩余执行时间，还剩7毫秒）和进程3。

![1348147234_1048](../img/1348147234_1048.png)

SJF调度是最优的调度，但难点在于如何预测进程的执行时间(Burst Time)。对于批处理系统中的长期调度来说，可以将用户
提交进程时输入的执行时间上限作为依据。但对于短期调度来说，没有办法能够提前得知下一个要被分配CPU的进程的执行
时间长短。我们只能通过历史数据来进行预测，公式如下：

<img src="../img/1348147255_8277.png" alt="1348147255_8277" style="zoom: 200%;" />

α可以取0.5，公式前半部分表示最近一次Burst Time，而后半部分表示过去历史平均的Burst Time。
该算法虽可获得较好的调度性能，但难以准确地知道下一个CPU执行期，而只能根据每一个进程的执行历史来预测。

**最短剩余时间**

最短剩余时间（Shortest Remaining Time,SRT）是针对SPN增加了抢占机制的版本。在这种情况下，调度程序总是选择预期剩余时间最短的进程。当一个进程加入就绪队列时，它可能比当前运行的进程具有更短的剩余时间，因此只要新进程就绪，调度程序就可能抢占当前正在运行的进程。像SPN一样，调度程序在执行选择函数时必须有关于处理时间的估计，并且存在长进程饥饿的危险。

**优先权调度算法**

1. 优先权调度算法的类型。为了照顾紧迫性作业，使之进入系统后便获得优先处理，引入了最高优先权优先（FPF）调度算法。 此算法常被用在批处理系统中，作为作业调度算法，也作为多种操作系统中的进程调度，还可以用于实时系统中。当其用于作业调度， 将后备队列中若干个优先权最高的作业装入内存。当其用于进程调度时，把处理机分配给就绪队列中优先权最高的进程，此时， 又可以进一步把该算法分成以下两种：

    1)非抢占式优先权算法

    2)抢占式优先权调度算法（高性能计算机操作系统）

  2. 优先权类型 。对于最高优先权优先调度算法，其核心在于：它是使用静态优先权还是动态优先权， 以及如何确定进程的优先权。 

  3. 高响应比优先调度算法 

为了弥补短作业优先算法的不足，我们引入动态优先权，使作业的优先等级随着等待时间的增加而以速率a提高。 该优先权变化规律可描述为：优先权=（等待时间+要求服务时间）/要求服务时间；即 =（响应时间）/要求服务时间

根据比率：R=(w+s)/s （R为响应比，w为等待处理的时间，s为预计的服务时间）

如果该进程被立即调用，则R值等于归一化周转时间（周转时间和服务时间的比率）。R最小值为1.0，只有第一个进入系统的进程才能达到该值。

调度规则为：在当前进程完成或被阻塞时，选择R值最大的就绪进程，它说明了进程的年龄。当偏向短作业时，长进程由于得不到服务，等待时间不断增加，从而增加比值，最终在竞争中胜了短进程。

和STR,SPN一样，使用最高响应比（HRRN）策略需要估计预计服务时间。

<img src="../img/1348147165_7418.png" alt="1348147165_7418" style="zoom: 150%;" />

<img src="../img/1348147192_1775.png" alt="1348147192_1775" style="zoom:150%;" />



采取基于优先级调度算法要考虑进程饿死的问题，因为高优先级的进程总是会被优先调度，具有低优先级的进程可能永远都不会被内核调度执行。Aging是对于这个问题的一个解决方案，所谓Aging就是指逐渐提高系统中长时间等待的进程的优先级。比如如果优先级的范围从127到0（127表示最低优先级），那么我们可以每15分钟将等待进程的优先级加1。最终经过一段时间，即便是拥有最低优先级127的进程也会变成系统中最高优先级的进程，从而被执行。
优先级调度可以抢占式或者非抢占式的。当一个进程在Ready队列中时，内核将它的优先级与正在CPU上执行的进程的优先级进行比较。当发现这个新进程的优先级比正在执行的进程高时：对于抢占式内核，新进程会抢占CPU，之前正在执行的进程转入Ready队列；对于非抢占式内核，新进程只会被放置在Ready队列的头部，不会抢占正在执行的进程。

**多级反馈队列调度算法**

多级反馈队列调度算法，不必事先知道各种进程所需要执行的时间，它是目前被公认的一种较好的进程调度算法。 其实施过程如下：

1) 设置多个就绪队列，并为各个队列赋予不同的优先级。在优先权越高的队列中， 为每个进程所规定的执行时间片就越小。
2) 当一个新进程进入内存后，首先放入第一队列的末尾，按FCFS原则排队等候调度。 如果他能在一个时间片中完成，便可撤离；如果未完成，就转入第二队列的末尾，在同样等待调度…… 如此下去，当一个长作业（进程）从第一队列依次将到第n队列（最后队列）后，便按第n队列时间片轮转运行。
3) 仅当第一队列空闲时，调度程序才调度第二队列中的进程运行；仅当第1到第（i-1）队列空时， 才会调度第i队列中的进程运行，并执行相应的时间片轮转。
4) 如果处理机正在处理第i队列中某进程，又有新进程进入优先权较高的队列， 则此新队列抢占正在运行的处理机，并把正在运行的进程放在第i队列的队尾。

如果没有关于各进程相对长度的任何信息，则SPN，SRT和HRRN都不能使用。另一种导致偏向短作业的方法是处罚运行时间较长的作业，换句话说，如果不能获得剩余的执行时间，那就关注已经执行了的时间。

方法为：调度基于抢占原则（按时间片）并且使用动态优先级机制。当一个进程第一次进入系统中时，它被放置在一个优先级队列中，当第一次被抢占后并返回就绪状态时，它被放置在下一个低优先级队列中，在随后的时间里，每当被抢占时，它被降级到下一个低优先级队列中。一个短进程很快会执行完，不会在就绪队列中降很多级，一个长进程会逐渐降级。因此新到的进程和短进程优先于老进程和长进程。在每个队列中，除了在优先级最低的队列中之外，都是用简单的FCFS机制，一旦一个进程处于优先级最低的队列中，它就不可能再降级，但会重复的返回该队列，知道运行结束。因此，该队列可按照轮转方式调度。

**抢占式调度算法**

1. 非抢占式调度算法

  为每一个被控对象建立一个实时任务并将它们排列成一轮转队列,调度程序每次选择队列中的第一个任务投入运行.该任务完成后便把它挂在轮转队列的队尾等待下次调度运行.

2. 非抢占式优先调度算法.

  实时任务到达时,把他们安排在就绪队列的对首,等待当前任务自我终止或运行完成后才能被调度执行.

3. 抢占式调度算法

  1）基于时钟中断的抢占式优先权调度算法.
  实时任务到达后,如果该任务的优先级别高于当前任务的优先级并不立即抢占当前任务的处理机,而是等到时钟中断到来时,调度程序才剥夺当前任务的执行,将处理机分配给新到的高优先权任务.

  2）立即抢占的优先权调度算法.
  在这种调度策略中,要求操作系统具有快速响应外部时间中断的能力.一旦出现外部中断,只要当前任务未处于临界区便立即剥夺当前任务的执行,把处理机分配给请求中断的紧迫任务，实时进程调度，实时进程抢占当前。
