## 引擎的区别

**MyISAM**

创建一个myisam存储引擎的表的时候回出现三个文件

1.tb_demo.frm，存储表定义； 2.tb_demo.MYD，存储数据； 3.tb_demo.MYI，存储索引。

MyISAM表无法处理事务，这就意味着有事务处理需求的表，不能使用MyISAM存储引擎。

MyISAM存储引擎特别适合在以下几种情况下使用：

1.选择密集型的表。MyISAM存储引擎在筛选大量数据时非常迅速，这是它最突出的优点。

2.插入密集型的表。MyISAM的并发插入特性允许同时选择和插入数据。例如：MyISAM存储引擎很适合管理邮件或Web服务器日志数据。

 

**InnoDB**

InnoDB是一个健壮的事务型存储引擎MySQL 5.6.版本以后InnoDB就是作为默认的存储引擎。

InnoDB还引入了行级锁定和外键约束，在以下场合下，使用InnoDB是最理想的选择：

1. 更新密集的表。InnoDB存储引擎特别适合处理多重并发的更新请求。
2. 事务。InnoDB存储引擎是支持事务的标准MySQL存储引擎。
3. 自动灾难恢复。与其它存储引擎不同，InnoDB表能够自动从灾难中恢复。
4. 外键约束。MySQL支持外键的存储引擎只有InnoDB。
5. 支持自动增加列AUTO_INCREMENT属性。

 

**MEMORY**

使用MySQL Memory存储引擎的出发点是速度。为得到最快的响应时间，采用的逻辑存储介质是系统内存。虽然在内存中存储表数据确实会提供很高的性能，但当mysqld守护进程崩溃时，所有的Memory数据都会丢失。获得速度的同时也带来了一些缺陷。它要求存储在Memory数据表里的数据使用的是长度不变的格式，这意味着不能使用BLOB和TEXT这样的长度可变的数据类型，VARCHAR是一种长度可变的类型，但因为它在MySQL内部当做长度固定不变的CHAR类型，所以可以使用。

一般在以下几种情况下使用Memory存储引擎：

1.目标数据较小，而且被非常频繁地访问。在内存中存放数据，所以会造成内存的使用，可以通过参数max_heap_table_size控制Memory表的大小，设置此参数，就可以限制Memory表的最大大小。

2.如果数据是临时的，而且要求必须立即可用，那么就可以存放在内存表中。

3.存储在Memory表中的数据如果突然丢失，不会对应用服务产生实质的负面影响。Memory同时支持散列索引和B树索引。B树索引的优于散列索引的是，可以使用部分查询和通配查询，也可以使用<、>和>=等操作符方便数据挖掘。散列索引进行“相等比较”非常快，但是对“范围比较”的速度就慢多了，因此散列索引值适合使用在=和<>的操作符中，不适合在<或>操作符中，也同样不适合用在order by子句中

 

**MERGE**

MERGE存储引擎是一组MyISAM表的组合，这些MyISAM表结构必须完全相同，尽管其使用不如其它引擎突出，但是在某些情况下非常有用。说白了，Merge表就是几个相同MyISAM表的聚合器；Merge表中并没有数据，对Merge类型的表可以进行查询、更新、删除操作，这些操作实际上是对内部的MyISAM表进行操作。Merge存储引擎的使用场景。对于服务器日志这种信息，一般常用的存储策略是将数据分成很多表，每个名称与特定的时间端相关。例如：可以用12个相同的表来存储服务器日志数据，每个表用对应各个月份的名字来命名。当有必要基于所有12个日志表的数据来生成报表，这意味着需要编写并更新多表查询，以反映这些表中的信息。与其编写这些可能出现错误的查询，不如将这些表合并起来使用一条查询，之后再删除Merge表，而不影响原来的数据，删除Merge表只是删除Merge表的定义，对内部的表没有任何影响。

 

**ARCHIVE**

archive是归档的意思，在归档之后很多的高级功能就不再支持了，仅仅支持最基本的插入和查询两种功能。在MySQL 5.5版以前，Archive是不支持索引，但是在MySQL 5.5以后的版本中就开始支持索引了。Archive拥有很好的压缩机制，它使用zlib压缩库，在记录被请求时会实时压缩，所以它经常被用来当做仓库使用。

 

比较常用的是MyISAM和InnoBD

|                                        | **MyISAM**                                                   | **InnoDB**                                                   |
| -------------------------------------- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| **构成上的区别：**                     | 每个MyISAM在磁盘上存储成三个文件。第一个文件的名字以表的名字开始，扩展名指出文件类型。<br />.frm文件存储表定义。<br />数据文件的扩展名为.MYD (MYData)。<br />索引文件的扩展名是.MYI (MYIndex)。 | 基于磁盘的资源是InnoDB表空间数据文件和它的日志文件，InnoDB 表的大小只受限于操作系统文件的大小，一般为 2GB |
| **事务处理上方面:**                    | MyISAM类型的表强调的是性能，其执行数度比InnoDB类型更快，但是不提供事务支持 | InnoDB提供事务支持事务，外部键（foreign key）等高级数据库功能 |
| **SELECT  UPDATE, INSERT，Delete操作** | 如果执行大量的SELECT，MyISAM是更好的选择                     | **1.**如果你的数据执行大量的**INSERT** **或** **UPDATE**，出于性能方面的考虑，应该使用InnoDB表   <br />**2.DELETE  FROM table**时，InnoDB不会重新建立表，而是一行一行的删除。<br />**3.LOAD  TABLE FROM MASTER**操作对InnoDB是不起作用的，解决方法是首先把InnoDB表改成MyISAM表，导入数据后再改成InnoDB表，但是对于使用的额外的InnoDB特性（例如外键）的表不适用 |
| **对AUTO_INCREMENT 的操作**            | 每表一个AUTO_INCREMEN列的内部处理。<br />**MyISAM** **为** **INSERT** **和** **UPDATE** **操作自动更新这一列**。这使得AUTO_INCREMENT列更快（至少10%）。在序列顶的值被删除之后就不能再利用。(当AUTO_INCREMENT列被定义为多列索引的最后一列，可以出现重使用从序列顶部删除的值的情况）。AUTO_INCREMENT值可用ALTER TABLE或myisamch来重置   对于AUTO_INCREMENT类型的字段，InnoDB中必须包含只有该字段的索引，但是在MyISAM表中，可以和其他字段一起建立联合索引   更好和更快的auto_increment处理 | 如果你为一个表指定AUTO_INCREMENT列，在数据词典里的InnoDB表句柄包含一个名为自动增长计数器的计数器，它被用在为该列赋新值。<br />自动增长计数器仅被存储在主内存中，而不是存在磁盘上<br />关于该计算器的算法实现，请参考   **AUTO_INCREMENT** **列在** **InnoDB** **里如何工作** |
| **表的具体行数**                       | select count(*) from table,MyISAM只要简单的读出保存好的行数，注意的是，当count(*)语句包含 where条件时，两种表的操作是一样的 | InnoDB 中不保存表的具体行数，也就是说，执行select count(*) from table时，InnoDB要扫描一遍整个表来计算有多少行 |
| **锁**                                 | 表锁                                                         | 提供行锁(locking on row level)，提供与 Oracle 类型一致的不加锁读取(non-locking read in   SELECTs)，另外，InnoDB表的行锁也不是绝对的，如果在执行一个SQL语句时MySQL不能确定要扫描的范围，InnoDB表同样会锁全表， 例如update table set num=1 where name like “�a%” |





## 事务的特性（ACID）

如果一个数据库声称支持事务的操作，那么该数据库必须要具备以下四个特性：

**⑴ 原子性（Atomicity）**

原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚，因此事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有任何影响，就像这个事务从来没有执行过一样。

**⑵ 一致性（Consistency）**

一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。一致性是指完整性约束不被破坏，完整性包含实体完整性（主属性不为空）、参照完整性（外键必须存在原表中）、用户自定义的完整性。

**⑶ 隔离性（Isolation）**

隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能被其他事务的操作所干扰，多个并发事务之间要相互隔离。

数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止**多个事务并发执行时由于交叉执行而导致数据的不一致**。**事务隔离**分为不同级别，包括读未提交（Read uncommitted）、读提交（read committed）、可重复读（repeatable read）和串行化（Serializable）。

**⑷ 持久性（Durability）**

持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。



## 隔离级别

1、读取数据时是否占用锁以及所请求的锁类型。

2、占用读取锁的时间。

3、引用其他事务修改的行的读取操作是否。

4、在该行上的写锁被释放之前阻塞其他事务。

5、检索在启动语句或事务时存在的行的已提交版本。

6、读取未提交的数据修改。

**若不考虑隔离性**

 1.**脏读**

脏读是指一个事务在处理数据的过程中，读取到另一个未提交事务的数据。

2.**不可重复读**

不可重复读是指对于数据库中的某个数据，一个事务范围内的多次查询却返回了不同的结果，这是由于在查询过程中，数据被另外一个事务修改并提交了。

3.**幻读**

指一个事务执行两次查询，但第二次查询的结果包含了第一次查询中未出现的数据。

例如事务T1对一个表中所有的行的某个数据项做了从“1”修改为“2”的操作，这时事务T2又对这个表中插入了一行数据项，而这个数据项的数值还是为“1”并且提交给数据库。而操作事务T1的用户如果再查看刚刚修改的数据，会发现还有一行没有修改，其实这行是从事务T2中添加的，就好像产生幻觉一样，这就是发生了幻读。

4.**丢失更新**

指两个事务同时更新一行数据，后提交（或撤销）的事务将之前事务提交的数据覆盖了。

丢失更新可分为两类，分别是第一类丢失更新和第二类丢失更新。

- 第一类丢失更新是指两个事务同时操作同一个数据时，当第一个事务撤销时，把已经提交的第二个事务的更新数据覆盖了，第二个事务就造成了数据丢失。
- 第二类丢失更新是指当两个事务同时操作同一个数据时，第一个事务将修改结果成功提交后，对第二个事务已经提交的修改结果进行了覆盖，对第二个事务造成了数据丢失。

**隔离级别**

1.**读未提交（Read uncommitted）**

这种事务隔离级别下，select语句不加锁。

此隔离级别可防止丢失更新。

2.**读已提交（Read committed）**

可避免 脏读 的发生。

3.**可重复读（Repeatable read）**

MySql默认隔离级别。

可避免 脏读 、不可重复读 的发生。

4.**串行化（Serializable ）**

可避免 脏读、不可重复读、幻读 的发生。



## 隔离级别的底层技术

[数据库事务特征、数据库隔离级别，以及各级别数据库加锁情况(含实操)--read uncommitted篇 - 简书 (jianshu.com)](https://www.jianshu.com/p/d75fcdeb07a3)

[MySQL数据库事务各隔离级别加锁情况--read committed && MVCC_慕课手记 (imooc.com)](http://www.imooc.com/article/17290)

[MySQL数据库事务各隔离级别加锁情况--Repeatable Read && MVCC_慕课手记 (imooc.com)](http://www.imooc.com/article/17289)

### MVCC

MVCC的全称是“多版本并发控制”。这项技术使得InnoDB的事务隔离级别下执行一致性读操作有了保证，换言之，就是为了查询一些正在被另一个事务更新的行，并且可以看到它们被更新之前的值。这是一个可以用来增强并发性的强大的技术，因为这样的一来的话查询就不用等待另一个事务释放锁。

InnoDB会给数据库中的每一行增加三个字段，它们分别是DB_TRX_ID、DB_ROLL_PTR、DB_ROW_ID。

> 在Mysql中MVCC是在Innodb存储引擎中得到支持的，Innodb为每行记录都实现了三个隐藏字段：
>
> 6字节的事务ID（DB_TRX_ID）
>
> 7字节的回滚指针（DB_ROLL_PTR）
>
> 隐藏的ID（DB_ROW_ID）
>
> 6字节的事物ID用来标识该行所属的事务，7字节的回滚指针需要了解下Innodb的事务模型。

**增删查改**

在InnoDB中，给每行增加两个隐藏字段来实现MVCC，一个用来记录数据行的创建时间，另一个用来记录行的过期时间（删除时间）。在实际操作中，存储的并不是时间，而是事务的版本号，每开启一个新事务，事务的版本号就会递增。

于是乎，默认的隔离级别（REPEATABLE READ）下，增删查改变成了这样：

- SELECT
  - 读取创建版本小于或等于当前事务版本号，并且删除版本为空或大于当前事务版本号的记录。这样可以保证在读取之前记录是存在的。
- INSERT
  - 将当前事务的版本号保存至行的创建版本号
- UPDATE
  - 新插入一行，并以当前事务的版本号作为新行的创建版本号，同时将原记录行的删除版本号设置为当前事务版本号
- DELETE
  - 将当前事务的版本号保存至行的删除版本号

**快照读和当前读**

快照读：读取的是快照版本，也就是历史版本

当前读：读取的是最新版本

普通的SELECT就是快照读，而UPDATE、DELETE、INSERT、SELECT ...  LOCK IN SHARE MODE、SELECT ... FOR UPDATE是当前读。



### 锁

- Shared Locks(共享锁/S锁)：

  若事务T对数据对象A加上S锁，则事务T只能读A；其他事务只能再对A加S锁，而不能加X锁，直到T释放A上的S锁。这就保证了其他事务可以读A，但在T释放A上的S锁之前不能对A做任何修改。

- Exclusive Locks（排他锁/X锁）：

  若事务T对数据对象A加上X锁，则只允许T读取和修改A，其它任何事务都不能再对A加任何类型的锁，直到T释放A上的锁。它防止任何其它事务获取资源上的锁，直到在事务的末尾将资源上的原始锁释放为止。在更新操作(INSERT、UPDATE 或 DELETE)过程中始终应用排它锁。

  注意：排他锁会阻止其它事务再对其**锁定的数据**加读或写的锁，但是不加锁的就没办法控制了。

- 更新锁（简记为U锁）：

  用来预定要对此对象施加X锁，它允许其他事务读，但不允许再施加U锁或X锁；当被读取的对象将要被更新时，则升级为X锁，主要是用来防止死锁的。因为使用共享锁时，修改数据的操作分为两步，首先获得一个共享锁，读取数据，然后将共享锁升级为排它锁，然后再执行修改操作。这样如果同时有两个或多个事务同时对一个对象申请了共享锁，在修改数据的时候，这些事务都要将共享锁升级为排它锁。这些事务都不会释放共享锁而是一直等待对方释放，这样就造成了死锁。如果一个数据在修改前直接申请更新锁，在数据修改的时候再升级为排它锁，就可以避免死锁。

- Record Locks（行锁）：

  行锁，顾名思义，是加在`索引行`(对！是索引行！不是数据行！)上的锁。比如`select * from user where id=1 and id=10 for update`，就会在`id=1`和`id=10`的索引行上加Record Lock。

- Gap Locks（间隙锁）：

  间隙锁，它会锁住两个索引之间的区域。比如`select * from user where id>1 and id<10 for update`，就会在id为(1,10)的索引区间上加Gap Lock。

- Next-Key Locks(间隙锁)：

  也叫间隙锁，它是Record Lock + Gap Lock形成的一个闭区间锁。比如`select * from user where id>=1 and id<=10 for update`，就会在id为[1,10]的索引闭区间上加Next-Key Lock。



**什么时候加锁**

在数据库增删改查四种操作中，insert、delete和update都是会加排它锁(Exclusive Locks)的，而select只有显式声明才会加锁:

- select: 即最常用的查询，是不加任何锁的
- select ... lock in share mode: 会加共享锁(Shared Locks)
- select ... for update: 会加排它锁



### 实现原理

**读未提交（READ UNCOMMITTED）**

顾名思义，事务之间可以读取彼此未提交的数据。

`READ UNCOMMITTED`隔离级别下, 读不会加任何锁。而写会加排他锁，并到事务结束之后释放。

实例1：

查-写：查并没有阻止写，表明查肯定并没有加锁，要不写肯定就阻塞了。写很明显，会加排它锁的。

实例2： 

写-写：阻塞，表明，写会加排它锁。

> 在READ UNCOMMITTED级别运行的事务不会发出共享锁，以防止其他事务修改当前事务读取的数据。读取UNCOMMITTED事务也不被排他锁阻止，这将阻止当前事务读取已被修改但未被其他事务提交的行。设置此选项时，可以读取未提交的修改，称为脏读。可以更改数据中的值，并且行可以在事务结束之前在数据集中显示或消失。此选项与在事务中的所有SELECT语句中的所有表上设置NOLOCK具有相同的效果。这是隔离级别的最小限制。

**读已提交（Read committed）**

顾名思义，事务之间可以读取彼此已提交的数据。

InnoDB在该隔离级别(READ COMMITTED)写数据时，使用排它锁, 读取数据不加锁而是使用了MVCC机制。

因此，在读已提交的级别下，都会通过**MVCC**获取当前数据的**最新**快照，不加任何锁，也无视任何锁(因为历史数据是构造出来的，身上不可能有锁)。以此**解决脏读**。

但是，该级别下还是遗留了不可重复读和幻读问题： **MVCC版本的生成时机**: 是每次**select**时。这就意味着，如果我们在事务A中执行多次的select，在每次select之间有其他事务**更新**了我们读取的数据并提交了，那就出现了**不可重复读**，即：重复读时，会出现数据不一致问题，后面我们会讲解超支现象，就是这种引起的。



**可重复读（Repeatable read）**

READ COMMITTED级别不同的是**MVCC版本的生成时机**，即：一次事务在创建trx结构时（第一次select时）生成版本，后续的查询都是在这个版本上进行，从而实现了**可重复读**。

1.读不影响写：事务以排他锁的形式修改原始数据，**读时不加锁**，因为 MySQL 在事务隔离级别Read committed 、Repeatable Read下，InnoDB 存储引擎采用非锁定性一致读－－即读取不占用和等待表上的锁。即采用的是MVCC中一致性非锁定读模式。因读时不加锁，所以不会阻塞其他事物在相同记录上加 X锁来更改这行记录。

2.写不影响读：事务以排他锁的形式修改原始数据，当读取的行正在执行 delete 或者 update 操作，这时读取操作不会因此去等待行上锁的释放。相反地，InnoDB 存储引擎会去读取行的一个快照数据。

此时虽然可避免不可重复读，但如果进行更新操作，就不是快照读了，而是当前读，可能会读到别的事务产生的数据。产生了幻读。



**串行化（Serializable）**

大杀器，该级别下，会自动将所有普通`select`转化为`select ... lock in share mode`执行，即针对同一数据的所有读写都变成互斥的了，可靠性大大提高，并发性大大降低。

读-写，写-写均互斥。



## 如何在RR模式下避免幻读

需要手动加锁将快照读调整为当前读（mysql不会自动加锁），然后mysql使用Next-Key Locks 避免了幻读。

这其实与串行化一致，只不过我们是在RR模式下特殊使用了共享锁。



## 分布式事务

[从银行转账失败到分布式事务：总结与思考 - xybaby - 博客园 (cnblogs.com)](https://www.cnblogs.com/xybaby/p/7465816.html)

[再论分布式事务：从理论到实践 - xybaby - 博客园 (cnblogs.com)](https://www.cnblogs.com/xybaby/p/7756163.html)



<img src="https://images2017.cnblogs.com/blog/1089769/201710/1089769-20171030194022777-1791638071.png" alt="img" style="zoom:150%;" />



<img src="https://images2017.cnblogs.com/blog/1089769/201710/1089769-20171031182622121-726504272.jpg" alt="img"  />

在上图中，使用了三种分布式事务解决办法：

（1）基于可靠消息的最终一致性方案（异步确保型），这个使用比较广，适用于分支事务大概率成功的情况；

上图中使用于：对应支付系统会计异步记账业务，银行通知结果信息存储与驱动订单处理

（2）TCC事务补偿性方案，使用在同时需要保证一致性与高性能的场景

对应上图中支付系统的订单账户操作：订单处理，资金账户处理，积分账户处理

（3）best effort，最大努力通知型方案，适用于跨平台之间的事务原子性保证

对应上图中支付系统的商户业务通知场景



## 索引分类

- 普通索引：用表中的普通列构建的索引，没有任何限制，用于加速查询
- 唯一索引：用来建立索引的类的值必须是唯一的，允许空值
  - 关键字：unique
  - 语法：create unique 索引名 on 表名(字段名);
  - 唯一约束的作用：列值不能重复，但是允许null；当给某个列添加唯一约束，会自动添加唯一索引
  - 约束：限制列的动作，包括添加修改值

- 主键索引：
  - 即主索引，根据主键pk_clolum（length）建立索引，不允许重复，不允许空值，是一种特殊的唯一索引，一个表只能有一个主键，不允许有空值。一般是在建表的时候同时创建主键索引。当列添加主键约束时，自动添加主键索引。

- 组合索引：用多个列组合构建的索引，这多个列中的值不允许有空值
  - 语法：create index 索引名 on 表名(字段1,字段2);

- 全文索引：用大文本对象的列构建的索引，主要用来查找文件中的关键字。
  - 关键字：fulltext
  - 语法：create fulltext index 索引名 on 表名(字段名);



## 索引结构

数据库索引，是数据库管理系统中一个排序的数据结构，以协助快速查询、更新数据库表中数据。索引的实现通常使用B树及其变种B+树。

### B树

B树（Balance Tree）又叫做B- 树（其实B-是由B-tree翻译过来，所以B-树和B树是一个概念） ，它就是一种平衡多路查找树。下图就是一个典型的B树： 
![这里写图片描述](https://img-blog.csdn.net/20160926140212457)

详细定义：

> 1. 有一个根节点，根节点只有一个记录和两个孩子或者根节点为空；
> 2. 每个节点记录中的key和指针相互间隔，指针指向孩子节点；
> 3. d是表示树的宽度，除叶子节点之外，其它每个节点有[d/2,d-1]条记录，并且些记录中的key都是从左到右按大小排列的，有[d/2+1,d]个孩子；
> 4. 在一个节点中，第n个子树中的所有key，小于这个节点中第n个key，大于第n-1个key，比如上图中B节点的第2个子节点E中的所有key都小于B中的第2个key 9，大于第1个key 3;
> 5. 所有的叶子节点必须在同一层次，也就是它们具有相同的深度；

由于B-Tree的特性，在B-Tree中按key检索数据的算法非常直观：首先从根节点进行二分查找，如果找到则返回对应节点的data，否则对相应区间的指针指向的节点递归进行查找，直到找到节点或找到null指针，前者查找成功，后者查找失败。B-Tree上查找算法的伪代码如下：

```kotlin
BTree_Search(node, key) {
     if(node == null) return null;
     foreach(node.key){
          if(node.key[i] == key) return node.data[i];
          if(node.key[i] > key) return BTree_Search(point[i]->node);
      }
     return BTree_Search(point[i+1]->node);
  }
data = BTree_Search(root, my_key);
```

关于B-Tree有一系列有趣的性质，例如一个度为d的B-Tree，设其索引N个key，则其树高h的上限为`logd((N+1)/2)`，检索一个key，其查找节点个数的渐进复杂度为`O(logdN)`。从这点可以看出，B-Tree是一个非常有效率的索引数据结构。

另外，由于插入删除新的数据记录会破坏B-Tree的性质，因此在插入删除时，需要对树进行一个分裂、合并、转移等操作以保持B-Tree性质，本文不打算完整讨论B-Tree这些内容，因为已经有许多资料详细说明了B-Tree的数学性质及插入删除算法，有兴趣的朋友可以查阅其它文献进行详细研究。



### **B+树**

其实B-Tree有许多变种，其中最常见的是B+Tree，比如MySQL就普遍使用B+Tree实现其索引结构。B-Tree相比，B+Tree有以下不同点：

- 每个节点的指针上限为2d而不是2d+1；
- 内节点不存储data，只存储key；
- 叶子节点不存储指针；

下面是一个简单的B+Tree示意。 

![这里写图片描述](https://img-blog.csdn.net/20160926140413000)

由于并不是所有节点都具有相同的域，因此B+Tree中叶节点和内节点一般大小不同。这点与B-Tree不同，虽然B-Tree中不同节点存放的key和指针可能数量不一致，但是每个节点的域和上限是一致的，所以在实现中B-Tree往往对每个节点申请同等大小的空间。一般来说，B+Tree比B-Tree更适合实现外存储索引结构，具体原因与外存储器原理及计算机存取原理有关，将在下面讨论。

**带有顺序访问指针的B+Tree**

一般在数据库系统或文件系统中使用的B+Tree结构都在经典B+Tree的基础上进行了优化，增加了顺序访问指针。 
![这里写图片描述](https://img-blog.csdn.net/20160926140641162)

如图所示，在B+Tree的每个叶子节点增加一个指向相邻叶子节点的指针，就形成了带有顺序访问指针的B+Tree。做这个优化的目的是为了提高区间访问的性能，例如图4中如果要查询key为从18到49的所有数据记录，当找到18后，只需顺着节点和指针顺序遍历就可以一次性访问到所有数据节点，极大提到了区间查询效率。

### InnoDB B+树

InnoDB的数据文件本身就是索引文件。在InnoDB中，表数据文件本身就是按B+Tree组织的一个索引结构，这棵树的叶节点data域保存了完整的数据记录。这个索引的key是数据表的主键，因此InnoDB表数据文件本身就是主索引。 

![这里写图片描述](https://img-blog.csdn.net/20160926141856136)

上图是InnoDB主索引（同时也是数据文件）的示意图，可以看到叶节点包含了完整的数据记录。这种索引叫做聚集索引。因为InnoDB的数据文件本身要按主键聚集，所以InnoDB要求表必须有主键，如果没有显式指定，则MySQL系统会自动选择一个可以唯一标识数据记录的列作为主键，如果不存在这种列，则MySQL自动为InnoDB表生成一个隐含字段作为主键，这个字段长度为6个字节，类型为长整形。



InnoDB的辅助索引data域存储相应记录主键的值而不是地址。换句话说，InnoDB的所有辅助索引都引用主键作为data域。例如，下图为定义在Col3上的一个辅助索引： 

![这里写图片描述](https://img-blog.csdn.net/20160926141926745)

这里以英文字符的ASCII码作为比较准则。聚集索引这种实现方式使得按主键的搜索十分高效，但是辅助索引搜索需要检索两遍索引：首先检索辅助索引获得主键，然后用主键到主索引中检索获得记录。

了解不同存储引擎的索引实现方式对于正确使用和优化索引都非常有帮助，例如知道了InnoDB的索引实现后，就很容易明白为什么不建议使用过长的字段作为主键，因为所有辅助索引都引用主索引，过长的主索引会令辅助索引变得过大。再例如，用非单调的字段作为主键在InnoDB中不是个好主意，因为InnoDB数据文件本身是一颗B+Tree，非单调的主键会造成在插入新记录时数据文件为了维持B+Tree的特性而频繁的分裂调整，十分低效，而使用自增字段作为主键则是一个很好的选择。

**联合索引**

- 对于联合索引来说只不过比单值索引多了几列。
- 联合索引的所有索引列都出现在索引树上，并依次顺序比较几个列的大小。
- InnoDB引擎会首先根据第一个索引列“单调递增”排序，如果第一列相等则再根据第二列排序，依次类推.

(b,c,d) 联合索引的所有索引列都出现在索引数上，并依次比较b,c,d三列的大小。

![bcd联合索引在B+树上的结构图](https://imgconvert.csdnimg.cn/aHR0cHM6Ly91c2VyLWdvbGQtY2RuLnhpdHUuaW8vMjAyMC8yLzI3LzE3MDg2N2NiNmFmMGE3MmQ?x-oss-process=image/format,png)

### 为什么不用红黑树或是B树

**红黑树**

1.红黑树必须存在内存里的，数据库表太大了，存不进去。

2.即使你找到了把红黑树存进硬盘的方法，红黑树查找一个节点最多要查logN层，每一层都是一个内存页（虽然你只是想找一个节点，但硬盘必须一次读一个页。。），那么一共logN次IO。

所以需要用b+树减少树的高度

**B树**

1.b树的内部节点都是存储实际数据的，比如一个节点是一个页4096字节，其中每条数据128字节，那么一个节点只能存32个数据项，那么对应的孩子节点数最多为33个，这显然不够用。而b+树内部节点只作为导向作用，只存一个整数就可以，4096/4=1024个数据项。这样b+树的每个节点的孩子数更多，整个树的高度就更低，大大增加查询效率。

2.b+树的叶子节点可以有链表相连，适合范围查询，因为相邻页直接读取就好了。但b树做不到这一点。



## 索引的结构优化

**联合索引（复合索引）**

首先介绍一下联合索引。联合索引其实很简单，相对于一般索引只有一个字段，联合索引可以为多个字段创建一个索引。它的原理也很简单，比如，我们在（a,b,c）字段上创建一个联合索引，则索引记录会首先按照A字段排序，然后再按照B字段排序然后再是C字段，因此，联合索引的特点就是：

- 第一个字段一定是有序的

- 当第一个字段值相等的时候，第二个字段又是有序的，比如下表中当A=2时所有B的值是有序排列的，依次类推，当同一个B值得所有C字段是有序排列的

  | A | B | C | 
  | 1 | 2 | 3 | 
  | 1 | 4 | 2 | 
  | 1 | 1 | 4 | 
  | 2 | 3 | 5 | 
  | 2 | 4 | 4 | 
  | 2 | 4 | 6 | 
  | 2 | 5 | 5 |

其实联合索引的查找就跟查字典是一样的，先根据第一个字母查，然后再根据第二个字母查，或者只根据第一个字母查，但是不能跳过第一个字母从第二个字母开始查。这就是所谓的最左前缀原理。

**最左前缀原理**

我们再来详细介绍一下联合索引的查询。还是上面例子，我们在`（a,b,c）`字段上建了一个联合索引，所以这个索引是先按a 再按b 再按c进行排列的，所以：

以下的查询方式都可以用到索引

```sql
select * from table where a=1；
select * from table where a=1 and b=2；
select * from table where a=1 and b=2 and c=3；
```

上面三个查询按照 `（a ）, （a，b ）,（a，b，c ）`的顺序都可以利用到索引，这就是最左前缀匹配。

如果查询语句是：

```sql
select * from table where a=1 and c=3； 那么只会用到索引a。
```

如果查询语句是：

```sql
select * from table where b=2 and c=3； 因为没有用到最左前缀a，所以这个查询是用户到索引的。
```

如果用到了最左前缀，但是顺序颠倒会用到索引码？

比如：

```sql
select * from table where b=2 and a=1；
select * from table where b=2 and a=1 and c=3；
```

如果用到了最左前缀而只是颠倒了顺序，也是可以用到索引的，因为mysql查询优化器会判断纠正这条sql语句该以什么样的顺序执行效率最高，最后才生成真正的执行计划。但我们还是最好按照索引顺序来查询，这样查询优化器就不用重新编译了。

**前缀索引**

除了联合索引之外，对mysql来说其实还有一种前缀索引。前缀索引就是用列的前缀代替整个列作为索引key，当前缀长度合适时，可以做到既使得前缀索引的选择性接近全列索引，同时因为索引key变短而减少了索引文件的大小和维护开销。

一般来说以下情况可以使用前缀索引：

- 字符串列(varchar,char,text等)，需要进行全字段匹配或者前匹配。也就是=‘xxx’ 或者 like ‘xxx%’
- 字符串本身可能比较长，而且前几个字符就开始不相同。比如我们对中国人的姓名使用前缀索引就没啥意义，因为中国人名字都很短，另外对收件地址使用前缀索引也不是很实用，因为一方面收件地址一般都是以XX省开头，也就是说前几个字符都是差不多的，而且收件地址进行检索一般都是like ’%xxx%’，不会用到前匹配。相反对外国人的姓名可以使用前缀索引，因为其字符较长，而且前几个字符的选择性比较高。同样电子邮件也是一个可以使用前缀索引的字段。
- 前一半字符的索引选择性就已经接近于全字段的索引选择性。如果整个字段的长度为20，索引选择性为0.9，而我们对前10个字符建立前缀索引其选择性也只有0.5，那么我们需要继续加大前缀字符的长度，但是这个时候前缀索引的优势已经不明显，没有太大的建前缀索引的必要了。

一些文章中也提到：

MySQL 前缀索引能有效减小索引文件的大小，提高索引的速度。但是前缀索引也有它的坏处：MySQL 不能在 ORDER BY 或 GROUP BY 中使用前缀索引，也不能把它们用作覆盖索引(Covering Index)。

**策略**

- 最左前缀匹配原则，上面讲到了
- 主键外键一定要建索引
- 对 where,on,group by,order by 中出现的列使用索引
- 尽量选择区分度高的列作为索引,区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就是0
- 对较小的数据列使用索引,这样会使索引文件更小,同时内存中也可以装载更多的索引键
- 索引列不能参与计算，保持列“干净”，比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’);
- 为较长的字符串使用前缀索引
- 尽量的扩展索引，不要新建索引。比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可
- 不要过多创建索引, 权衡索引个数与DML之间关系，DML也就是插入、删除数据操作。这里需要权衡一个问题，建立索引的目的是为了提高查询效率的，但建立的索引过多，会影响插入、删除数据的速度，因为我们修改的表数据，索引也需要进行调整重建
- 对于like查询，”%”不要放在前面。 
  `SELECT * FROM`houdunwang`WHERE`uname`LIKE'后盾%' -- 走索引` 
  `SELECT * FROM`houdunwang`WHERE`uname`LIKE "%后盾%" -- 不走索引`
- 查询where条件数据类型不匹配也无法使用索引 
  字符串与数字比较不使用索引; 
  `CREATE TABLE`a`(`a`char(10));` 
  `EXPLAIN SELECT * FROM`a`WHERE`a`="1"` – 走索引 
  EXPLAIN SELECT * FROM `a` WHERE `a`=1 – 不走索引 
  正则表达式不使用索引,这应该很好理解,所以为什么在SQL中很难看到regexp关键字的原因



## SQL题

[经典SQL练习题(MySQL版)_廖致君的博客-CSDN博客_mysql练习](https://blog.csdn.net/paul0127/article/details/82529216)
