## 进程和线程

一、**线程的基本概念**

线程是进程中执行运算的最小单位，是进程中的一个实体，是被系统独立调度和分派的基本单位，线程自己不拥有系统资源，只拥有一点在运行中必不可少的资源，但它可与同属一个进程的其它线程共享进程所拥有的全部资源。一个线程可以创建和撤消另一个线程，同一进程中的多个线程之间可以并发执行。

好处 ：

（1）易于调度。

（2）提高并发性。通过线程可方便有效地实现并发性。进程可创建多个线程来执行同一程序的不同部分。

（3）开销少。创建线程比创建进程要快，所需开销很少。

（4）利于充分发挥多处理器的功能。通过创建多线程进程，每个线程在一个处理器上运行，从而实现应用程序的并发性，使每个处理器都得到充分运行。

二、**进程与线程**

**进程：**每个进程都有独立的代码和数据空间（进程上下文），进程间的切换会有较大的开销，一个进程包含1--n个线程。（进程是资源分配的最小单位）

**线程：**同一类线程共享代码和数据空间，每个线程有独立的运行栈和程序计数器(PC)，线程切换开销小。（线程是cpu调度的最小单位）

线程和进程一样分为五个阶段：**创建、就绪、运行、阻塞、终止。**

![img](https://images2018.cnblogs.com/blog/1418466/201808/1418466-20180813190253839-297059020.png)

![img](https://images2018.cnblogs.com/blog/1418466/201808/1418466-20180813190923313-2036091644.png)

 

**多进程是指操作系统能同时运行多个任务（程序）。**

**多线程是指在同一程序中有多个顺序流在执行。**

每个正在系统上运行的程序都是一个进程。每个进程包含一到多个线程。进程也可能是整个程序或者是部分程序的动态执行。线程是一组指令的集合，或者是程序的特殊段，它可以在程序里独立执行。也可以把它理解为代码运行的上下文。所以线程基本上是轻量级的进程，它负责在单个程序里执行多任务。通常由操作系统负责多个线程的调度和执行。

在Java中，一个应用程序可以包含多个线程。每个线程执行特定的任务，并可与其他线程并发执行多线程使系统的空转时间最少，提高CPU利用率、多线程编程环境用方便的模型隐藏CPU在任务间切换的事实在Java程序启动时，一个线程立刻运行，该线程通常称为程序的主线程。

主线程的重要性体现在两个方面：

1、它是产生其他子线程的线程。

2、通常它必须最后完成执行，因为它执行各种关闭动作。

三、**进程与线程的区别**：

（1）调度：线程作为调度和分配的基本单位，进程作为拥有资源的基本单位

（2）并发性：不仅进程之间可以并发执行，同一个进程的多个线程之间也可并发执行

（3）拥有资源：进程是拥有资源的一个独立单位，线程不拥有系统资源，但可以访问隶属于进程的资源.

（4）系统开销：在创建或撤消进程时，由于系统都要为之分配和回收资源，导致系统的开销明显大于创建或撤消线程时的开销。

 四、**同步和互斥的区别**：

当有多个线程的时候，经常需要去同步这些线程以访问同一个数据或资源。例如，假设有一个程序，其中一个线程用于把文件读到内存，而另一个线程用于统计文件中的字符数。当然，在把整个文件调入内存之前，统计它的计数是没有意义的。但是，由于每个操作都有自己的线程，操作系统会把两个线程当作是互不相干的任务分别执行，这样就可能在没有把整个文件装入内存时统计字数。为解决此问题，你必须使两个线程同步工作。

所谓同步，是指散步在不同进程之间的若干程序片断，它们的运行必须严格按照规定的某种先后次序来运行，这种先后次序依赖于要完成的特定的任务。如果用对资源的访问来定义的话，同步是指在互斥的基础上（大多数情况），通过其它机制实现访问者对资源的有序访问。在大多数情况下，同步已经实现了互斥，特别是所有写入资源的情况必定是互斥的。少数情况是指可以允许多个访问者同时访问资源。

所谓互斥，是指散布在不同进程之间的若干程序片断，当某个进程运行其中一个程序片段时，其它进程就不能运行它们之中的任一程序片段，只能等到该进程运行完这个程序片段后才可以运行。如果用对资源的访问来定义的话，互斥某一资源同时只允许一个访问者对其进行访问，具有唯一性和排它性。但互斥无法限制访问者对资源的访问顺序，即访问是无序的。

 五、**进程间通信的方式**？

（1）管道（pipe）及有名管道（named pipe）：管道可用于具有亲缘关系的父子进程间的通信，有名管道除了具有管道所具有的功能外，它还允许无亲缘关系进程间的通信。

（2）信号（signal）：信号是在软件层次上对中断机制的一种模拟，它是比较复杂的通信方式，用于通知进程有某事件发生，一个进程收到一个信号与处理器收到一个中断请求效果上可以说是一致的。

（3）消息队列（message queue）：消息队列是消息的链接表，它克服了上两种通信方式中信号量有限的缺点，具有写权限得进程可以按照一定得规则向消息队列中添加新信息；对消息队列有读权限得进程则可以从消息队列中读取信息。

（4）共享内存（shared memory）：可以说这是最有用的进程间通信方式。它使得多个进程可以访问同一块内存空间，不同进程可以及时看到对方进程中对共享内存中数据得更新。这种方式需要依靠某种同步操作，如互斥锁和信号量等。

（5）信号量（semaphore）：主要作为进程之间及同一种进程的不同线程之间得同步和互斥手段。

（6）套接字（socket）：这是一种更为一般得进程间通信机制，它可用于网络中不同机器之间的进程间通信，应用非常广泛。

 六、**进程和线程的关系**：

（1）一个线程只能属于一个进程，而一个进程可以有多个线程，但至少有一个线程。

（2）资源分配给进程，同一进程的所有线程共享该进程的所有资源。

（3）处理机分给线程，即真正在处理机上运行的是线程。

（4）线程在执行过程中，需要协作同步。不同进程的线程间要利用消息通信的办法实现同步。线程是指进程内的一个执行单元,也是进程内的可调度实体.

 七、**多线程的优点**

- 使用线程可以把占据时间长的程序中的任务放到后台去处理


- 用户界面可以更加吸引人，这样比如用户点击了一个按钮去触发某些事件的处理，可以弹出一个进度条来显示处理的进度


- 程序的运行速度可能加快


- 在一些等待的任务实现上如用户输入、文件读写和网络收发数据等，线程就比较有用了。在这种情况下可以释放一些珍贵的资源如内存占用等等。

- 多线程技术在IOS软件开发中也有举足轻重的位置。

八、**多线程的缺点**

- 如果有大量的线程,会影响性能,因为操作系统需要在它们之间切换。
- 更多的线程需要更多的内存空间。
- 线程可能会给程序带来更多“bug”，因此要小心使用。
- 线程的中止需要考虑其对程序运行的影响。
- 通常块模型数据是在多个线程间共享的，需要防止线程死锁情况的发生。

九、线程的共享资源

| 线程共享资源 | 线程独享资源 |
| :----------- | ------------ |
| 地址空间     | 程序计数器   |
| 全局变量     | 寄存器       |
| 打开的文件   | 栈           |
| 子进程       | 状态字       |

### **总结**

线程和进程的区别在于，子进程和父进程有不同的代码和数据空间，而多个线程则共享数据空间，每个线程有自己的执行堆栈和程序计数器为其执行上下文。多线程主要是为了节约CPU时间，发挥利用，根据具体情况而定，线程的运行中需要使用计算机的内存资源和CPU。



在CPU看来所有的任务都是一个一个的轮流执行的，具体的轮流方法就是：**先加载进程A的上下文，然后开始执行A，保存进程A的上下文，调入下一个要执行的进程B的进程上下文，然后开始执行B,保存进程B的上下文**

进程和线程就是这样的背景出来的，两个名词不过是对应的CPU时间段的描述，名词就是这样的功能。

- **进程就是上下文切换之间的程序执行的部分。是运行中的程序的描述，也是对应于该段CPU执行时间的描述。**
- **在软件编码方面，我们说的进程，其实是稍不同的，编程语言中创建的进程是一个无限loop，对应的是tcb块。这个是操作系统进行调度的单位。所以和上面的cpu执行时间段还是不同的。**
- **进程，与之相关的东东有寻址空间，寄存器组，[堆栈空间](https://www.zhihu.com/search?q=堆栈空间&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A81152571})等。即不同的进程，这些东东都不同，从而能相互区别。**

**线程是什么呢？**

进程的颗粒度太大，每次的执行都要进行进程上下文的切换。

程序A得到CPU =》CPU加载上下文，开始执行程序A的a小段，然后执行A的b小段，然后再执行A的c小段，最后CPU保存A的上下文。

这里a，b，c的执行是共享了A进程的上下文，CPU在执行的时候仅仅切换线程的上下文，而没有进行进程上下文切换的。进程的上下文切换的时间开销是远远大于线程上下文时间的开销。这样就让CPU的有效使用率得到提高。这**里的a，b，c就是线程，也就是说线程是共享了进程的上下文环境，的更为细小的CPU时间段。线程主要共享的是进程的[地址空间](https://www.zhihu.com/search?q=地址空间&search_source=Entity&hybrid_search_source=Entity&hybrid_search_extra={"sourceType"%3A"answer"%2C"sourceId"%3A81152571})。**

**进程和线程都是一个时间段的描述，是CPU工作时间段的描述，不过是颗粒大小不同。**



## 线程和协程

操作系统在线程等待IO的时候，会阻塞当前线程，切换到其它线程，这样在当前线程等待IO的过程中，其它线程可以继续执行。当系统线程较少的时候没有什么问题，但是当线程数量非常多的时候，却产生了问题。**一是系统线程会占用非常多的内存空间，二是过多的线程切换会占用大量的系统时间。**

协程运行在线程之上，当一个协程执行完成后，可以选择主动让出，让另一个协程运行在当前线程之上。**协程并没有增加线程数量，只是在线程的基础之上通过分时复用的方式运行多个协程**，而且协程的切换在用户态完成，切换的代价比线程从用户态到内核态的代价小很多。

**注意事项**

假设协程运行在线程之上，并且协程调用了一个阻塞IO操作，这时候会发生什么？实际上操作系统并不知道协程的存在，它只知道线程，**因此在协程调用阻塞IO操作的时候，操作系统会让线程进入阻塞状态，当前的协程和其它绑定在该线程之上的协程都会陷入阻塞而得不到调度，这往往是不能接受的。**

因此在协程中不能调用导致线程阻塞的操作。也就是说，协程只有和异步IO结合起来，才能发挥最大的威力。

那么如何处理在协程中调用阻塞IO的操作呢？一般有2种处理方式：

1. **在调用阻塞IO操作的时候，重新启动一个线程去执行这个操作，等执行完成后，协程再去读取结果。这其实和多线程没有太大区别。**
2. **对系统的IO进行封装，改成异步调用的方式，这需要大量的工作，最好寄希望于编程语言原生支持。**

协程对计算密集型的任务也没有太大的好处，计算密集型的任务本身不需要大量的线程切换，因此协程的作用也十分有限，反而还增加了协程切换的开销。

**异步变同步的调用方式只是一种编程方式，不管是用线程还是用协程都可以实现这种编程方式，好处是不用在处理非常多的回调。**

### **总结**

在有大量IO操作业务的情况下，我们采用协程替换线程，可以到达很好的效果，一是降低了系统内存，二是减少了系统切换开销，因此系统的性能也会提升。

在协程中尽量不要调用阻塞IO的方法，比如打印，读取文件，Socket接口等，除非改为异步调用的方式，并且协程只有在IO密集型的任务中才会发挥作用。

**协程只有和异步IO结合起来才能发挥出最大的威力。**

------

## 进程间通信的方式

- 消息传递（管道、FIFO、消息队列）
- 同步（互斥量、条件变量、读写锁、文件和写记录锁、信号量）
- 共享内存（匿名的和具名的）
- 远程过程调用（Solaris门和Sun RPC）

1. 管道pipe：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程间使用。进程的亲缘关系通常是指父子进程关系。
2. 命名管道FIFO：有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。
3. 消息队列MessageQueue：消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
4. 共享存储SharedMemory：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制，如信号量，配合使用，来实现进程间的同步和通信。
5. 信号量Semaphore：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
6. 套接字Socket：套解口也是一种进程间通信机制，与其他通信机制不同的是，它可用于不同及其间的进程通信。
7. 信号 ( sinal ) ： 信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。

**管道**

管道，通常指无名管道，是 UNIX 系统IPC最古老的形式。

特点：
它是半双工的（即数据只能在一个方向上流动），具有固定的读端和写端。

它只能用于具有亲缘关系的进程之间的通信（也是父子进程或者兄弟进程之间）。

它可以看成是一种特殊的文件，对于它的读写也可以使用普通的read、write 等函数。但是它不是普通的文件，并不属于其他任何文件系统，并且只存在于内存中。

管道分为pipe（无名管道）和fifo（命名管道）两种，除了建立、打开、删除的方式不同外，这两种管道几乎是一样的。他们都是通过内核缓冲区实现数据传输。

pipe用于相关进程之间的通信，例如父进程和子进程，它通过pipe()系统调用来创建并打开，当最后一个使用它的进程关闭对他的引用时，pipe将自动撤销。

FIFO即命名管道，在磁盘上有对应的节点，但没有数据块——换言之，只是拥有一个名字和相应的访问权限，通过mknode()系统调用或者mkfifo()函数来建立的。一旦建立，任何进程都可以通过文件名将其打开和进行读写，而不局限于父子进程，当然前提是进程对FIFO有适当的访问权。当不再被进程使用时，FIFO在内存中释放，但磁盘节点仍然存在。

管道的实质是一个内核缓冲区，进程以先进先出的方式从缓冲区存取数据：管道一端的进程顺序地将进程数据写入缓冲区，另一端的进程则顺序地读取数据，该缓冲区可以看做一个循环队列，读和写的位置都是自动增加的，一个数据只能被读一次，读出以后再缓冲区都不复存在了。当缓冲区读空或者写满时，有一定的规则控制相应的读进程或写进程是否进入等待队列，当空的缓冲区有新数据写入或慢的缓冲区有数据读出时，就唤醒等待队列中的进程继续读写。

**消息队列**

消息队列，就是一个消息的链表，是一系列保存在内核中消息的列表。用户进程可以向消息队列添加消息，也可以向消息队列读取消息。

消息队列与管道通信相比，其优势是对每个消息指定特定的消息类型，接收的时候不需要按照队列次序，而是可以根据自定义条件接收特定类型的消息。

可以把消息看做一个记录，具有特定的格式以及特定的优先级。对消息队列有写权限的进程可以向消息队列中按照一定的规则添加新消息，对消息队列有读权限的进程可以从消息队列中读取消息。

**共享内存**

共享内存允许两个或多个进程共享一个给定的存储区，这一段存储区可以被两个或两个以上的进程映射至自身的地址空间中，一个进程写入共享内存的信息，可以被其他使用这个共享内存的进程，通过一个简单的内存读取错做读出，从而实现了进程间的通信。

采用共享内存进行通信的一个主要好处是效率高，因为进程可以直接读写内存，而不需要任何数据的拷贝，对于像管道和消息队里等通信方式，则需要再内核和用户空间进行四次的数据拷贝，而共享内存则只拷贝两次：一次从输入文件到共享内存区，另一次从共享内存到输出文件。

一般而言，进程之间在共享内存时，并不总是读写少量数据后就解除映射，有新的通信时在重新建立共享内存区域；而是保持共享区域，直到通信完毕为止，这样，数据内容一直保存在共享内存中，并没有写回文件。共享内存中的内容往往是在解除映射时才写回文件，因此，采用共享内存的通信方式效率非常高。

**信号量**

信号量（semaphore）与已经介绍过的 IPC 结构不同，它是一个计数器。信号量用于实现进程间的互斥与同步，而不是用于存储进程间通信数据。

1、特点
信号量用于进程间同步，若要在进程间传递数据需要结合共享内存。

信号量基于操作系统的 PV 操作，程序对信号量的操作都是原子操作。

每次对信号量的 PV 操作不仅限于对信号量值加 1 或减 1，而且可以加减任意正整数。

支持信号量组。

2、原型
最简单的信号量是只能取 0 和 1 的变量，这也是信号量最常见的一种形式，叫做二值信号量（Binary Semaphore）。而可以取多个正整数的信号量被称为通用信号量。

Linux 下的信号量函数都是在通用的信号量数组上进行操作，而不是在一个单一的二值信号量上进行操作。

**socket**

IP层的ip地址可以唯一标示主机，而TCP层协议和端口号可以唯一标示主机的一个进程，这样我们可以利用ip地址＋协议＋端口号唯一标示网络中的一个进程。

能够唯一标示网络中的进程后，它们就可以利用socket进行通信了。socket是在应用层和传输层之间的一个抽象层，它把TCP/IP层复杂的操作抽象为几个简单的接口供应用层调用已实现进程在网络中通信。

------

## 锁的类型

### 互斥锁

互斥锁指代相互排斥，它是最基本的同步方式。互斥锁用于保护临界区，以保证任何时刻只有一个线程在执行其中的代码（假设互斥锁由多个线程共享），或者任何时刻只有一个进程在执行其中的代码。

**特点**

- 多个线程访问共享数据的时候是串行的
- 效率低

**Barkey锁**

- 每个线程想进入临界区之前都会升起自己的旗帜，并得到一个序号。然后升起旗帜的线程中序号最小的线程才能进入临界区。 
- 每个线程离开临界区的时候降下自己的旗帜。

### 读写锁

读写锁用于读与写之间作区分。读写锁的分配规则如下：

1. 只要没有线程持有某个给定的读写锁用于读或用于写时，那么任意数目的线程可以持有该读写锁用于读。
2. 仅当没有线程持有某个给定的读写锁用于读或用于写时，才能分配该读写锁用于写。

**特点**

- 读共享 - 并行处理，线程A加读锁成功, 又来了三个线程, 做读操作, 可以加锁成功
- 写独占，线程A加写锁成功, 又来了三个线程, 做读操作, 三个线程阻塞
- 读写不能同时，写的优先级高，线程A加读锁成功, 又来了B线程加写锁阻塞, 又来了C线程加读锁阻塞

**适用场景**

程序中的读操作>写操作的时候

### 乐观锁和悲观锁

**悲观锁**

总是假设最坏的情况，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会阻塞直到它拿到锁（共享资源每次只给一个线程使用，其它线程阻塞，用完后再把资源转让给其它线程）。传统的关系型数据库里边就用到了很多这种锁机制，比如行锁，表锁等，读锁，写锁等，都是在做操作之前先上锁。

**乐观锁**

总是假设最好的情况，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在更新的时候会判断一下在此期间别人有没有去更新这个数据，可以使用版本号机制和CAS算法实现。乐观锁适用于多读的应用类型，这样可以提高吞吐量。

------

## 虚拟内存

一、 **虚拟地址空间**

在早期的计算机中，程序是直接运行在物理内存上的，那个时候的计算机和程序内存都很小。程序运行时会把其全部加载到内存，只要程序所需的内存不超过计算机剩余内存就不会出现问题。

 但由于程序是可以直接访问物理内存的，这也带来了内存数据的不安全性，轻则程序挂掉，重则操作系统崩溃。

 所以，我们希望程序间的内存数据是安全的互不影响的。同时计算机程序直接运行在物理内存上也导致了内存使用率较低，程序运行内存地址不确定，不同的运行顺序甚至会出错。此时在程序的执行过程中，已经存在着大量在物理内存和硬盘之间的数据交换过程。

 基于以上问题，那我们可以是不是考虑在物理内存之上增加一个中间层，让程序通过虚拟地址去间接的访问物理内存呢。通过虚拟内存，每个进程好像都可以独占内存一样，每个进程看到的内存都是一致的，这称为虚拟地址空间。（这种思想在现在也用的很广泛，例如很多优秀的中间层：Nginx、Redis等等）

 这样只要系统处理好虚拟地址到物理地址的映射关系，就可以保证不同的程序访问不同的内存区域，就可以达到物理内存地址隔离的效果，进而保证数据的安全性。

 

二、**分段与分页**

进程是操作系统资源分配的最小单元。操作系统分配给进程的内存空间中包含五种段：数据段、代码段、BSS、堆、栈。

- 数据段：存放程序中的静态变量和已初始化且不为零的全局变量。


- 代码段：存放可执行文件的操作指令，代码段是只读的，不可进行写操作。这部分的区域在运行前已知其大小。


- BSS段( Block Started By Symbol)：存放未初始化的全局变量，在变量使用前由运行时初始化为零。


- 堆：存放进程运行中被动态分配的内存，其大小不固定。


- 栈：存放程序中的临时的局部变量和函数的参数值。


 ![640?wx_fmt=png](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9KYmlhZUtucEd1NmlhTHM5ZWs2eGZaZUxFMkd6c3RKRk5Cd1daRUx3VkNuRndRUFpOTU4wNFlwM2JuRnBMaWI0VVVKUW5PZXNVVlBQVmdveFZyUXV4UWZpYWcvNjQw?x-oss-process=image/format,png)



那么分段的技术可以解决什么问题呢？

> 假设程序A的虚拟地址空间是0x00000000~0x00000099，映射到的物理地址空间是0x00000600~0x00000699，程序B的虚拟地址空间是0x00000100~0x00000199，映射到的物理地址空间是0x00000300~0x00000399。
>
> 假设你手残，在程序A中操作了地址0x00000150，但是此时的地址0x00000150是虚拟的，而虚拟化的操作是在操作系统的掌控中的，所以，操作系统有能力判断，这个虚拟地址0x00000150是有问题的，然后阻止后续的操作。所以，这里体现出了隔离性。（另一种体现隔离性的方式就是，操作同一个虚拟地址，实际上可能操作的是不同的物理地址）

所以通过分段机制，我们可以更好的控制不同段的属性，这有利于内存的组织安排，可以对不同的属性代码、数据进行更方便的管理。如果是打乱的放在内存中，那么读写属性就很难控制。

程序运行地址和物理地址的隔离保证了程序内存数据的安全性，也解决了同一个程序运行地址不确定的问题，但是物理内存使用效率低下的问题依然没有得到解决，因为分段机制映射的是一片连续的物理内存。

于是大佬们又提出了分页的办法。分页其实就是把段空间更细分了一下，粒度更小。此时物理内存被划分为一小块一小块，每块被称为帧(Frame)。分配内存时，帧是分配时的最小单位。

在分段方法中，每次程序的运行都会被全部加载到虚拟内存中；而分页方法则不同，单位不是整个程序，而是某个“页”，一段虚拟地址空间组成的某一页映射到一段物理地址空间组成的某一页。它将少部分要运行的代码加载到虚拟内存中，通过映射在物理内存中运行，从而提高了物理内存的使用率。

![640?wx_fmt=jpeg](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X2pwZy9KYmlhZUtucEd1NmlhTHM5ZWs2eGZaZUxFMkd6c3RKRk5CZzVOM0xjU2ljYjFLbnBneThMQzNRUkJVRThlaWFyaWNGUWlhenJIZlRkWk9KSHRCeFJONkZZaktwQS82NDA?x-oss-process=image/format,png)


为了方便CPU高效执行管理物理内存，每一次都需要从虚拟内存中拿一个页的代码放到物理内存。虚拟内存页有三种状态，分别是未分配、已缓存和未缓存状态。

**未分配**：指的是未被操作系统分配或者创建的，未分配的虚拟页不存在任何数据和代码与它们关联，因此不占用磁盘资源；

**已缓存**：表示的是物理内存中已经为该部分分配的，存在虚拟内存和物理内存映射关系的；

**未缓存**：指的是已经加载到虚拟内存中的，但是未在物理内存中建立映射关系的。

 

三、**页表**


虚拟内存中的一些虚拟页是要缓存在物理内存中才能被执行的，因此操作系统存在一种机制用来判断某个虚拟页是否被缓存在物理内存中，还需要知道这个虚拟页存放在磁盘上的哪个位置，从而在物理内存中选择空闲页或者更新缓存页，并将需要的虚拟页从磁盘复制到物理内存中。这些功能是由软硬件结合完成的，其存放在物理内存中一个叫页表的数据结构中。

虚拟内存和物理内存的映射通过页表(page table)来实现。每个页表实际上是一个数组，数组中的每个元素称为页表项(PTE, page table entry)，每个页表项负责把虚拟页映射到物理页上。在 物理内存中，每个进程都有自己的页表。

![img](https://imgconvert.csdnimg.cn/aHR0cHM6Ly9tbWJpei5xcGljLmNuL21tYml6X3BuZy9KYmlhZUtucEd1NmlhTHM5ZWs2eGZaZUxFMkd6c3RKRk5CbUhqeDVleGdkMU5WdHF1UE9lTDRsaWJMc3NiN09DRTU1a0Uyek51SkpYSk9nT29uRGJWZFBpYncvNjQw?x-oss-process=image/format,png)

因为有一个表可查询，就会遇到两种情况，一种是命中(Page Hit)，另一种则是未命中(Page Fault)。

命中的时候，即访问到页表中蓝色条目的地址时，因为在 DRAM 中有对应的数据，可以直接访问。

不命中的时候，即访问到 page table 中灰色条目的时候，因为在 DRAM 中并没有对应的数据，所以需要执行缺页置换。

在上图中，四个虚拟页VP1 , VP2, VP4 , VP7 是被缓存在物理内存中。两个虚拟页VP0, VP5还未被分配。但是剩下的虚拟页VP3 ,VP6已经被分配了，但是还没有缓存到物理内存中去执行。

四、**总结**
通过虚拟地址空间和页表的回顾，现在大家应该明白为什么要引入虚拟内存了吧。

虚拟内存是计算机系统内存管理的一种技术，虚拟地址空间构成虚拟内存。它使得应用程序认为它拥有连续可用的内存（一个连续完整的地址空间），而实际上，它通常是被分隔成多个物理内存碎片。还有部分暂时存储在外部磁盘存储器上（Swap），在需要时进行数据交换。

虚拟内存不只是用磁盘空间来扩展物理内存 的意思——这只是扩充内存级别以使其包含硬盘驱动器而已。把内存扩展到磁盘只是使用虚拟内存技术的一个结果。除了扩展内存空间，虚拟内存技术还有隔离运行内存和确定运行地址的作用。

使用虚拟内存主要是基于以下三个方面考虑，也就是说虚拟内存主要有三个作用：

- 作为缓存工具，提高内存利用率：使用 DRAM 当做部分的虚拟地址空间的缓存（虚拟内存就是存储在磁盘上的 N 个连续字节的数组，数组的部分内容会缓存在 DRAM 中）。扩大了内存空间，当发生缺页异常时，将会把内存和磁盘中的数据进行置换。


- 作为内存管理工具，简化内存管理：每个进程都有统一的线性地址空间（但实际上在物理内存中可能是间隔、支离破碎的），在内存分配中没有太多限制，每个虚拟页都可以被映射到任何的物理页上。这样也带来一个好处，如果两个进程间有共享的数据，那么直接指向同一个物理页即可。


- 作为内存保护工具，隔离地址空间：进程之间不会相互影响；用户程序不能访问内核信息和代码。页表中的每个条目的高位部分是表示权限的位，MMU 可以通过检查这些位来进行权限控制（读、写、执行）。

------

## 缺页中断

**缺页中断**

在请求分页系统中，可以通过查询页表中的状态位来确定所要访问的页面是否存在于内存中。每当所要访问的页面不在内存时，会产生一次缺页中断，此时操作系统会根据页表中的外存地址在外存中找到所缺的一页，将其调入内存。

缺页本身是一种中断，与一般的中断一样，需要经过4个处理步骤：

　　1. 保护CPU现场
　　2. 分析中断原因
　　3. 转入缺页中断处理程序进行处理
  4. 恢复CPU现场，继续执行

但是缺页中断时由于所要访问的页面不存在与内存时，有硬件所产生的一种特殊的中断，因此，与一般的中断存在区别：

   1. 在指令执行期间产生和处理缺页中断信号
   2. 一条指令在执行期间，可能产生多次缺页中断
   3. 缺页中断返回时，执行产生中断的那一条指令，而一般的中断返回时，执行下一条指令

**页面置换算法**

进程运行过程中，如果发生缺页中断，而此时内存中有没有空闲的物理块是，为了能够把所缺的页面装入内存，系统必须从内存中选择一页调出到磁盘的对换区。但此时应该把那个页面换出，则需要根据一定的页面置换算法（Page Replacement Algorithm)来确定。

**最近最久未使用置换算法（Least Recently Used， LRU）**

置换最近一段时间以来最长时间未访问过的页面。根据程序局部性原理，刚被访问的页面，可能马上又要被访问；而较长时间内没有被访问的页面，可能最近不会被访问。

LRU算法普偏地适用于各种类型的程序，但是系统要时时刻刻对各页的访问历史情况加以记录和更新，开销太大，因此LRU算法必须要有硬件的支持。

**堆栈**实现LRU：

系统使用特殊的堆栈来存放内存中每一个页面的页号。每当访问一页时就调整一次，即把被访问页面的页号从栈中移出再压入栈顶。因此，栈顶始终是最新被访问页面的页号，栈底始终是最近最久未被访问的页号。当发生缺页中断时，总是淘汰栈底页号所对应的页面。



------



## 内存分配

一、**代码区**

代码区是用来储存程序的所有代码，以及字符串常量等在编译期间就能确定的值，在程序的整个生命周期内， 在常量数据区的数据都是可用的。在这个区域内，所有的数据都是只读的，不可以修改本区域的数据，之所以这样，是因为在实际的实现中，最底层内部存储格式的实现会使用特定的优化方案。比如说，编译器可能只把字符串常量存储一次，而在几个重叠的对象里面引用它 。

二、**栈区**

栈区主要存放编译器在需要的时候自动分配，在不需要的时候自动销毁的变量。主要是局部变量和函数的参数等，在函数调用和传参的时候，编译器为局部变量或形参开辟空间，注意，在这块空间中，编译器并不会自动对它进行任何的初始化，它所保存的不是0，而是一个随机值（可能是该储存区上次被使用后的值），在函数结束后，所开辟的空间将自动销毁，里面所存的内容将不复存在，也就是释放存储区的内容。 这就是为什么老师们在讲课中，最喜欢用的字眼：参数压栈和弹出。

三、**全局静态（数据）区**

全局静态（数据）区是用来存储全局静态变量的存储区域。只有在程序启动的时候才被分配，直到程序开始执行时才被初始化，比如：函数的静态变量就是在程序执行到定义该变量的代码时才被初始化的。在静态区数据区中没有被初始化的区域可以通过void* 指针来访问或操纵，但是，static定义的静态变量只能在本文件中使用，不可在其它文件中声明使用。

四、**堆区**

堆区是一个动态的存储区域，使用库函数malloc()和free()，和操作符new和delete以及一些相关变量来进行分配和回收，在堆区中，对象的生命周期可以比它村在内存中的生命周期短，换句话说：程序可以获得一片内存区域而不用马上对它进行初始化，同时，在对象被销毁后，也不用马上收回它所占用的内存区，在这段时间内，用户可以还可以用void*型的指针访问这片区域，但是原始对象的非静态区以及成员函数都不能被访问或者操纵，因为我们知道实际上对象已经不存在了。

![图四](https://img-blog.csdnimg.cn/img_convert/f108aa64f7a104628ff1f1ab07f59968.png)
